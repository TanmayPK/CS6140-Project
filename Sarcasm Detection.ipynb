{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead11495",
   "metadata": {},
   "source": [
    "# CS6140 Project - Detection Of Sarcasm In Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f775377",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b434d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if running notebook with vectors locally for first time. Files added to gitignore\n",
    "# glove = api.load('glove-wiki-gigaword-300')\n",
    "# glove.save('glovevectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381c69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f39b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load('glovevectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae6077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad469e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b389d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these if not up to date\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d44928",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a7d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['label', 'comment', 'subreddit', 'score', 'parent_comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d40f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't pay attention to her, but as long as s...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0</td>\n",
       "      <td>do you find ariana grande sexy ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Trick or treating in general is just weird...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1</td>\n",
       "      <td>What's your weird or unsettling Trick or Treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Blade Mastery+Masamune or GTFO!</td>\n",
       "      <td>FFBraveExvius</td>\n",
       "      <td>2</td>\n",
       "      <td>Probably Sephiroth. I refuse to taint his grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>You don't have to, you have a good build, buy ...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>1</td>\n",
       "      <td>What to upgrade? I have $500 to spend (mainly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>I would love to see him at lolla.</td>\n",
       "      <td>Lollapalooza</td>\n",
       "      <td>2</td>\n",
       "      <td>Probably count Kanye out Since the rest of his...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0                                         NC and NH.   \n",
       "1      0  You do know west teams play against west teams...   \n",
       "2      0  They were underdogs earlier today, but since G...   \n",
       "3      0  This meme isn't funny none of the \"new york ni...   \n",
       "4      0                    I could use one of those tools.   \n",
       "5      0  I don't pay attention to her, but as long as s...   \n",
       "6      0      Trick or treating in general is just weird...   \n",
       "7      0                    Blade Mastery+Masamune or GTFO!   \n",
       "8      0  You don't have to, you have a good build, buy ...   \n",
       "9      0                  I would love to see him at lolla.   \n",
       "\n",
       "            subreddit  score  \\\n",
       "0            politics      2   \n",
       "1                 nba     -4   \n",
       "2                 nfl      3   \n",
       "3  BlackPeopleTwitter     -8   \n",
       "4  MaddenUltimateTeam      6   \n",
       "5           AskReddit      0   \n",
       "6           AskReddit      1   \n",
       "7       FFBraveExvius      2   \n",
       "8        pcmasterrace      1   \n",
       "9        Lollapalooza      2   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  \n",
       "5                   do you find ariana grande sexy ?  \n",
       "6  What's your weird or unsettling Trick or Treat...  \n",
       "7  Probably Sephiroth. I refuse to taint his grea...  \n",
       "8  What to upgrade? I have $500 to spend (mainly ...  \n",
       "9  Probably count Kanye out Since the rest of his...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f02bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label              0\n",
       "comment           53\n",
       "subreddit          0\n",
       "score              0\n",
       "parent_comment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de29e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95a447af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label             0\n",
       "comment           0\n",
       "subreddit         0\n",
       "score             0\n",
       "parent_comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c0dc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment_tokens'] = data['comment']\n",
    "data['comment_tokens'] = data['comment_tokens'].str.lower()\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('can\\'t','can not',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('\\'d',' would',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('wouldn\\'t','would not',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('couldn\\'t','could not',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('[^\\w\\s]','', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f9dc121",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['parent_comment_tokens'] = data['parent_comment']\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.lower()\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('can\\'t','can not',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('\\'d',' would',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('wouldn\\'t','would not',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('couldn\\'t','could not',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('[^\\w\\s]','', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a3ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "def apply_lemmatizer(sentence):\n",
    "    return [lemma.lemmatize(token) for token in wordpunct_tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fda16cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"comment_tokens\"] = data.comment_tokens.apply(apply_lemmatizer)\n",
    "data[\"parent_comment_tokens\"] = data.parent_comment_tokens.apply(apply_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f971fd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>[nc, and, nh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>[you, do, know, west, team, play, against, wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>[they, were, underdog, earlier, today, but, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>[this, meme, isnt, funny, none, of, the, new, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>[i, could, use, one, of, those, tool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I don't pay attention to her, but as long as s...</td>\n",
       "      <td>[i, dont, pay, attention, to, her, but, a, lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trick or treating in general is just weird...</td>\n",
       "      <td>[trick, or, treating, in, general, is, just, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blade Mastery+Masamune or GTFO!</td>\n",
       "      <td>[blade, masterymasamune, or, gtfo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You don't have to, you have a good build, buy ...</td>\n",
       "      <td>[you, dont, have, to, you, have, a, good, buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I would love to see him at lolla.</td>\n",
       "      <td>[i, would, love, to, see, him, at, lolla]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0                                         NC and NH.   \n",
       "1  You do know west teams play against west teams...   \n",
       "2  They were underdogs earlier today, but since G...   \n",
       "3  This meme isn't funny none of the \"new york ni...   \n",
       "4                    I could use one of those tools.   \n",
       "5  I don't pay attention to her, but as long as s...   \n",
       "6      Trick or treating in general is just weird...   \n",
       "7                    Blade Mastery+Masamune or GTFO!   \n",
       "8  You don't have to, you have a good build, buy ...   \n",
       "9                  I would love to see him at lolla.   \n",
       "\n",
       "                                      comment_tokens  \n",
       "0                                      [nc, and, nh]  \n",
       "1  [you, do, know, west, team, play, against, wes...  \n",
       "2  [they, were, underdog, earlier, today, but, si...  \n",
       "3  [this, meme, isnt, funny, none, of, the, new, ...  \n",
       "4              [i, could, use, one, of, those, tool]  \n",
       "5  [i, dont, pay, attention, to, her, but, a, lon...  \n",
       "6  [trick, or, treating, in, general, is, just, w...  \n",
       "7                 [blade, masterymasamune, or, gtfo]  \n",
       "8  [you, dont, have, to, you, have, a, good, buil...  \n",
       "9          [i, would, love, to, see, him, at, lolla]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"comment\", \"comment_tokens\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "256f1e24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805fcede",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>[yeah, i, get, that, argument, at, this, point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>[the, blazer, and, maverick, the, west, 5, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>[theyre, favored, to, win]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "      <td>[deadass, dont, kill, my, buzz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "      <td>[yep, can, confirm, i, saw, the, tool, they, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>do you find ariana grande sexy ?</td>\n",
       "      <td>[do, you, find, ariana, grande, sexy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What's your weird or unsettling Trick or Treat...</td>\n",
       "      <td>[whats, your, weird, or, unsettling, trick, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Probably Sephiroth. I refuse to taint his grea...</td>\n",
       "      <td>[probably, sephiroth, i, refuse, to, taint, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What to upgrade? I have $500 to spend (mainly ...</td>\n",
       "      <td>[what, to, upgrade, i, have, 500, to, spend, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Probably count Kanye out Since the rest of his...</td>\n",
       "      <td>[probably, count, kanye, out, since, the, rest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      parent_comment  \\\n",
       "0  Yeah, I get that argument. At this point, I'd ...   \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...   \n",
       "2                            They're favored to win.   \n",
       "3                         deadass don't kill my buzz   \n",
       "4  Yep can confirm I saw the tool they use for th...   \n",
       "5                   do you find ariana grande sexy ?   \n",
       "6  What's your weird or unsettling Trick or Treat...   \n",
       "7  Probably Sephiroth. I refuse to taint his grea...   \n",
       "8  What to upgrade? I have $500 to spend (mainly ...   \n",
       "9  Probably count Kanye out Since the rest of his...   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [yeah, i, get, that, argument, at, this, point...  \n",
       "1  [the, blazer, and, maverick, the, west, 5, and...  \n",
       "2                         [theyre, favored, to, win]  \n",
       "3                    [deadass, dont, kill, my, buzz]  \n",
       "4  [yep, can, confirm, i, saw, the, tool, they, u...  \n",
       "5              [do, you, find, ariana, grande, sexy]  \n",
       "6  [whats, your, weird, or, unsettling, trick, or...  \n",
       "7  [probably, sephiroth, i, refuse, to, taint, hi...  \n",
       "8  [what, to, upgrade, i, have, 500, to, spend, m...  \n",
       "9  [probably, count, kanye, out, since, the, rest...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"parent_comment\", \"parent_comment_tokens\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d10a4dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['parent_comment_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f395e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a306fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['comment_tokens', 'parent_comment_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10c087b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_tokens</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nc, and, nh]</td>\n",
       "      <td>[yeah, i, get, that, argument, at, this, point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[you, do, know, west, team, play, against, wes...</td>\n",
       "      <td>[the, blazer, and, maverick, the, west, 5, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[they, were, underdog, earlier, today, but, si...</td>\n",
       "      <td>[theyre, favored, to, win]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[this, meme, isnt, funny, none, of, the, new, ...</td>\n",
       "      <td>[deadass, dont, kill, my, buzz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, could, use, one, of, those, tool]</td>\n",
       "      <td>[yep, can, confirm, i, saw, the, tool, they, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[i, dont, pay, attention, to, her, but, a, lon...</td>\n",
       "      <td>[do, you, find, ariana, grande, sexy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[trick, or, treating, in, general, is, just, w...</td>\n",
       "      <td>[whats, your, weird, or, unsettling, trick, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[blade, masterymasamune, or, gtfo]</td>\n",
       "      <td>[probably, sephiroth, i, refuse, to, taint, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[you, dont, have, to, you, have, a, good, buil...</td>\n",
       "      <td>[what, to, upgrade, i, have, 500, to, spend, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[i, would, love, to, see, him, at, lolla]</td>\n",
       "      <td>[probably, count, kanye, out, since, the, rest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_tokens  \\\n",
       "0                                      [nc, and, nh]   \n",
       "1  [you, do, know, west, team, play, against, wes...   \n",
       "2  [they, were, underdog, earlier, today, but, si...   \n",
       "3  [this, meme, isnt, funny, none, of, the, new, ...   \n",
       "4              [i, could, use, one, of, those, tool]   \n",
       "5  [i, dont, pay, attention, to, her, but, a, lon...   \n",
       "6  [trick, or, treating, in, general, is, just, w...   \n",
       "7                 [blade, masterymasamune, or, gtfo]   \n",
       "8  [you, dont, have, to, you, have, a, good, buil...   \n",
       "9          [i, would, love, to, see, him, at, lolla]   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [yeah, i, get, that, argument, at, this, point...  \n",
       "1  [the, blazer, and, maverick, the, west, 5, and...  \n",
       "2                         [theyre, favored, to, win]  \n",
       "3                    [deadass, dont, kill, my, buzz]  \n",
       "4  [yep, can, confirm, i, saw, the, tool, they, u...  \n",
       "5              [do, you, find, ariana, grande, sexy]  \n",
       "6  [whats, your, weird, or, unsettling, trick, or...  \n",
       "7  [probably, sephiroth, i, refuse, to, taint, hi...  \n",
       "8  [what, to, upgrade, i, have, 500, to, spend, m...  \n",
       "9  [probably, count, kanye, out, since, the, rest...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c66bc3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147d82c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010816</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010818</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010819</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010820</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label\n",
       "1010816      1\n",
       "1010817      1\n",
       "1010818      1\n",
       "1010819      1\n",
       "1010820      1\n",
       "1010821      1\n",
       "1010822      1\n",
       "1010823      1\n",
       "1010824      1\n",
       "1010825      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca35050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, train_size= 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55aea5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, train_size = 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52a4c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "X_val = X_val.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6ad017d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_tokens</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ok, we, may, need, a, riot, forgot, mega, thr...</td>\n",
       "      <td>[riot, forgot, about, bard, chime, spawning, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[handtyped]</td>\n",
       "      <td>[yeah, if, you, can, not, figure, out, how, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[so, youre, saying, so, should, abuse, child, ...</td>\n",
       "      <td>[watch, porn, totally, normal, outlet, for, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[of, course, it, doe]</td>\n",
       "      <td>[funny, it, prompt, more, when, i, walk, than,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[havoc, demon, blade, so, fun]</td>\n",
       "      <td>[i, would, take, havoc, over, outlaw, any, day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[you, forgot]</td>\n",
       "      <td>[have, you, determined, that, from, your, exte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[if, he, a, hetero, male, without, a, vasectom...</td>\n",
       "      <td>[i, think, you, could, have, gone, without, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[just, take, a, boat, im, sure, they, would, l...</td>\n",
       "      <td>[a, plane, ticket, to, australia, omg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[but, i, guess, there, no, problem, in, writin...</td>\n",
       "      <td>[that, you, can, be, a, cunt, regardless, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[so, what, youre, saying, is, that, in, spite,...</td>\n",
       "      <td>[i, adore, zizek, but, i, think, his, strength...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_tokens  \\\n",
       "0  [ok, we, may, need, a, riot, forgot, mega, thr...   \n",
       "1                                        [handtyped]   \n",
       "2  [so, youre, saying, so, should, abuse, child, ...   \n",
       "3                              [of, course, it, doe]   \n",
       "4                     [havoc, demon, blade, so, fun]   \n",
       "5                                      [you, forgot]   \n",
       "6  [if, he, a, hetero, male, without, a, vasectom...   \n",
       "7  [just, take, a, boat, im, sure, they, would, l...   \n",
       "8  [but, i, guess, there, no, problem, in, writin...   \n",
       "9  [so, what, youre, saying, is, that, in, spite,...   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [riot, forgot, about, bard, chime, spawning, s...  \n",
       "1  [yeah, if, you, can, not, figure, out, how, to...  \n",
       "2  [watch, porn, totally, normal, outlet, for, yo...  \n",
       "3  [funny, it, prompt, more, when, i, walk, than,...  \n",
       "4  [i, would, take, havoc, over, outlaw, any, day...  \n",
       "5  [have, you, determined, that, from, your, exte...  \n",
       "6  [i, think, you, could, have, gone, without, in...  \n",
       "7             [a, plane, ticket, to, australia, omg]  \n",
       "8  [that, you, can, be, a, cunt, regardless, of, ...  \n",
       "9  [i, adore, zizek, but, i, think, his, strength...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "090bc1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606463"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65adcc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af1acd68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Since comments are already preprocessed and tokenized,\n",
    "# the vectorizer only needs to take tokens as they are.\n",
    "tfidfVectorizer = TfidfVectorizer(analyzer=lambda tokens: tokens)\n",
    "corpus = pd.concat([X_train['comment_tokens'], X_train['parent_comment_tokens']])\n",
    "tfidfMatrix = tfidfVectorizer.fit_transform(corpus)\n",
    "vocabulary = tfidfVectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b8359e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212926, 284405)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62a752d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1212926x284405 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17837027 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the tfidf matrix has 2021546 rows,\n",
    "# where the 0 ~ 606462 rows represent original comments in the same order as those in dataset,\n",
    "# and the 606463 ~ 1212926 rows represent parent comments in the same order as those in dataset;\n",
    "# and the tfidf matrix has 395961 columns, each represents a word in the vocabulary.\n",
    "tfidfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed12f91b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 181271,\n",
       " 'we': 272360,\n",
       " 'may': 158055,\n",
       " 'need': 172153,\n",
       " 'a': 18980,\n",
       " 'riot': 214362,\n",
       " 'forgot': 100715,\n",
       " 'mega': 159701,\n",
       " 'thread': 251714,\n",
       " 'soon': 234710,\n",
       " 'handtyped': 116402,\n",
       " 'so': 233427,\n",
       " 'youre': 282123,\n",
       " 'saying': 220977,\n",
       " 'should': 228390,\n",
       " 'abuse': 20164,\n",
       " 'child': 57400,\n",
       " 'can': 52270,\n",
       " 'have': 117676,\n",
       " 'more': 166675,\n",
       " 'porn': 196398,\n",
       " 'of': 180477,\n",
       " 'course': 66495,\n",
       " 'it': 132925,\n",
       " 'doe': 79844,\n",
       " 'havoc': 117755,\n",
       " 'demon': 74673,\n",
       " 'blade': 43281,\n",
       " 'fun': 103694,\n",
       " 'you': 281931,\n",
       " 'if': 126544,\n",
       " 'he': 118107,\n",
       " 'hetero': 119908,\n",
       " 'male': 154945,\n",
       " 'without': 276304,\n",
       " 'vasectomy': 266751,\n",
       " 'and': 26926,\n",
       " 'his': 121322,\n",
       " 'reproductive': 211499,\n",
       " 'fate': 95368,\n",
       " 'were': 273545,\n",
       " 'to': 253605,\n",
       " 'be': 38799,\n",
       " 'placed': 193673,\n",
       " 'in': 128175,\n",
       " 'the': 250000,\n",
       " 'hand': 116199,\n",
       " 'another': 27839,\n",
       " 'would': 277782,\n",
       " 'indeed': 128739,\n",
       " 'woman': 276750,\n",
       " 'whose': 274891,\n",
       " 'identity': 126278,\n",
       " 'at': 32759,\n",
       " 'this': 251240,\n",
       " 'point': 195167,\n",
       " 'is': 132341,\n",
       " 'arbitrary': 30306,\n",
       " 'aka': 23748,\n",
       " 'some': 234301,\n",
       " 'just': 137286,\n",
       " 'take': 246178,\n",
       " 'boat': 44636,\n",
       " 'im': 127294,\n",
       " 'sure': 243924,\n",
       " 'they': 250801,\n",
       " 'let': 147303,\n",
       " 'but': 50271,\n",
       " 'i': 125580,\n",
       " 'guess': 113654,\n",
       " 'there': 250563,\n",
       " 'no': 174932,\n",
       " 'problem': 199950,\n",
       " 'writing': 278565,\n",
       " 'law': 145583,\n",
       " 'that': 249758,\n",
       " 'try': 257943,\n",
       " 'fix': 98539,\n",
       " 'cunt': 69364,\n",
       " 'issue': 132827,\n",
       " 'what': 273970,\n",
       " 'spite': 236687,\n",
       " 'fact': 93912,\n",
       " 'havent': 117712,\n",
       " 'read': 207580,\n",
       " 'harris': 117166,\n",
       " 'book': 45500,\n",
       " 'certain': 55440,\n",
       " 'zizek': 283812,\n",
       " 'making': 154796,\n",
       " 'criticism': 67908,\n",
       " 'hasnt': 117369,\n",
       " 'who': 274696,\n",
       " 'doesnt': 79885,\n",
       " 'brought': 48386,\n",
       " 'chip': 57678,\n",
       " 'didnt': 76986,\n",
       " 'any': 29092,\n",
       " 'dip': 77769,\n",
       " 'president': 199029,\n",
       " 'guaranteed': 113513,\n",
       " 'very': 267802,\n",
       " 'lucrative': 152272,\n",
       " 'life': 148175,\n",
       " 'after': 22426,\n",
       " 'wh': 273869,\n",
       " 'want': 271169,\n",
       " 'look': 150895,\n",
       " 'hundred': 124611,\n",
       " 'million': 162871,\n",
       " 'clinton': 60120,\n",
       " 'made': 153832,\n",
       " 'leaving': 146217,\n",
       " '150': 3658,\n",
       " 'good': 110583,\n",
       " 'game': 105127,\n",
       " 'seems': 223646,\n",
       " 'like': 148537,\n",
       " 'steal': 239204,\n",
       " 'suppose': 243809,\n",
       " 'rating': 206733,\n",
       " 'not': 177684,\n",
       " 'high': 120392,\n",
       " 'now': 178285,\n",
       " 'kinglake': 140814,\n",
       " 'massive': 157243,\n",
       " 'fire': 97942,\n",
       " 'wa': 270327,\n",
       " 'before': 39540,\n",
       " 'yeah': 280790,\n",
       " 'all': 24632,\n",
       " 'top': 254508,\n",
       " 'support': 243749,\n",
       " 'lcs': 145869,\n",
       " 'or': 183521,\n",
       " 'even': 91162,\n",
       " 'general': 107099,\n",
       " 'wave': 272083,\n",
       " 'clear': 59774,\n",
       " 'joking': 136299,\n",
       " 'wat': 271781,\n",
       " 'really': 207817,\n",
       " 'snaked': 232895,\n",
       " 'my': 169743,\n",
       " 'boot': 45738,\n",
       " 'careful': 53282,\n",
       " 'dont': 80511,\n",
       " 'ruin': 217605,\n",
       " 'their': 250184,\n",
       " 'parade': 187613,\n",
       " 'dream': 82194,\n",
       " 'maybe': 158070,\n",
       " 'than': 249664,\n",
       " 'enough': 88809,\n",
       " 'know': 141716,\n",
       " 'worstim': 277694,\n",
       " 'looking': 150922,\n",
       " 'cleveland': 59923,\n",
       " 'college': 61599,\n",
       " 'aged': 22665,\n",
       " 'student': 241402,\n",
       " 'are': 30538,\n",
       " 'adult': 21765,\n",
       " 'date': 71781,\n",
       " 'each': 84646,\n",
       " 'other': 184407,\n",
       " 'wait': 270679,\n",
       " 'people': 190217,\n",
       " 'celebrating': 55020,\n",
       " 'comment': 62263,\n",
       " 'far': 94949,\n",
       " 'down': 81396,\n",
       " 'innocent': 129952,\n",
       " 'until': 263952,\n",
       " 'proven': 201405,\n",
       " 'guilty': 113814,\n",
       " 'phrase': 192194,\n",
       " 'your': 282119,\n",
       " 'parent': 187822,\n",
       " 'still': 239904,\n",
       " 'hope': 122980,\n",
       " 'for': 100394,\n",
       " 'playing': 194232,\n",
       " 'spore': 237041,\n",
       " 'dandylion': 71119,\n",
       " 'which': 274280,\n",
       " 'probably': 199899,\n",
       " 'run': 217752,\n",
       " 'tg': 249537,\n",
       " 'hyper': 125278,\n",
       " 'librarian': 147971,\n",
       " 'formula': 100825,\n",
       " 'synchron': 245290,\n",
       " 'armades': 30933,\n",
       " 'keeper': 139193,\n",
       " 'boundary': 46370,\n",
       " 'shooting': 228107,\n",
       " 'quasar': 203923,\n",
       " 'dragon': 81875,\n",
       " 'only': 182475,\n",
       " 'could': 66184,\n",
       " 'muslim': 169357,\n",
       " 'rebel': 208097,\n",
       " 'every': 91338,\n",
       " 'nation': 171242,\n",
       " 'stop': 240283,\n",
       " 'with': 276232,\n",
       " 'dumb': 83619,\n",
       " 'joke': 136237,\n",
       " 'guy': 114378,\n",
       " 'teenager': 248124,\n",
       " 'serious': 225238,\n",
       " '100': 852,\n",
       " 'time': 252688,\n",
       " 'bois': 44994,\n",
       " 'sfws': 225944,\n",
       " 'town': 255281,\n",
       " 'freeswag': 102012,\n",
       " 'happen': 116623,\n",
       " 'ear': 84708,\n",
       " 'sayin': 220974,\n",
       " 'better': 41135,\n",
       " 'put': 203029,\n",
       " 'bad': 35922,\n",
       " 'review': 212880,\n",
       " 'on': 181983,\n",
       " 'steam': 239243,\n",
       " 'whether': 274261,\n",
       " 'laugh': 145396,\n",
       " 'cry': 68539,\n",
       " 'right': 213949,\n",
       " 'think': 251069,\n",
       " 'coldplay': 61442,\n",
       " 'wouldve': 278203,\n",
       " 'been': 39430,\n",
       " 'much': 168236,\n",
       " 'sneaking': 233025,\n",
       " 'shadow': 226086,\n",
       " 'waiting': 270712,\n",
       " 'perfect': 190520,\n",
       " 'opportunity': 183286,\n",
       " 'strike': 241100,\n",
       " 'enemy': 88417,\n",
       " 'then': 250364,\n",
       " 'retreat': 212602,\n",
       " 'back': 35607,\n",
       " 'into': 131299,\n",
       " 'hiding': 120333,\n",
       " 'definitely': 73837,\n",
       " 'batmanlike': 38152,\n",
       " 'well': 273173,\n",
       " 'obviously': 180000,\n",
       " 'work': 277320,\n",
       " 'out': 184623,\n",
       " 'fine': 97740,\n",
       " 'print': 199600,\n",
       " 'later': 145252,\n",
       " 'brain': 46887,\n",
       " 'storming': 240459,\n",
       " 'phase': 191726,\n",
       " 'spamming': 235720,\n",
       " 'shit': 227524,\n",
       " 'see': 223550,\n",
       " 'how': 123733,\n",
       " 'helpful': 119224,\n",
       " 'market': 156632,\n",
       " 'everyday': 91348,\n",
       " 'fixed': 98553,\n",
       " 'do': 79624,\n",
       " 'okay': 181298,\n",
       " 'help': 119208,\n",
       " 'someone': 234346,\n",
       " 'confirm': 63558,\n",
       " 'theyve': 250849,\n",
       " 'done': 80403,\n",
       " 'because': 39139,\n",
       " 'play': 194059,\n",
       " '60hz': 14705,\n",
       " 'also': 25429,\n",
       " 'recording': 208642,\n",
       " 'setup': 225563,\n",
       " 'geared': 106653,\n",
       " 'capture': 52961,\n",
       " '60': 14536,\n",
       " 'fps': 101332,\n",
       " 'constantly': 64267,\n",
       " 'adjust': 21515,\n",
       " 'rate': 206678,\n",
       " 'swap': 244574,\n",
       " 'console': 64163,\n",
       " 'midcapture': 162102,\n",
       " 'must': 169417,\n",
       " 'talented': 246278,\n",
       " 'make': 154709,\n",
       " 'replica': 211323,\n",
       " 'ps4': 201637,\n",
       " 'xb1': 279373,\n",
       " 'controller': 64716,\n",
       " 'many': 156117,\n",
       " 'red': 208767,\n",
       " 'hearing': 118436,\n",
       " 'released': 210427,\n",
       " 'wild': 275357,\n",
       " 'when': 274199,\n",
       " 'confronted': 63653,\n",
       " 'actually': 21099,\n",
       " 'argument': 30753,\n",
       " 'highly': 120559,\n",
       " 'political': 195598,\n",
       " 'pretty': 199247,\n",
       " 'blame': 43369,\n",
       " 'everything': 91423,\n",
       " 'obama': 179569,\n",
       " 'lol': 150438,\n",
       " 'compared': 62654,\n",
       " 'him': 120964,\n",
       " 'legolas': 146740,\n",
       " 'watch': 271794,\n",
       " 'lotr': 151346,\n",
       " 'wasnt': 271700,\n",
       " 'trying': 257964,\n",
       " 'mean': 159030,\n",
       " 'sound': 235171,\n",
       " 'talk': 246316,\n",
       " 'about': 19909,\n",
       " 'again': 22536,\n",
       " 'c': 51103,\n",
       " 'envy': 89188,\n",
       " 'rn': 215013,\n",
       " '20': 6045,\n",
       " 'day': 72016,\n",
       " 'least': 146149,\n",
       " 'spell': 236285,\n",
       " 'favorite': 95630,\n",
       " 'color': 61750,\n",
       " 'correctly': 65681,\n",
       " 'buffed': 49179,\n",
       " 'mastodon': 157412,\n",
       " 'halberd': 115647,\n",
       " 'lacking': 144076,\n",
       " 'damage': 70876,\n",
       " 'counter': 66257,\n",
       " 'hooray': 122946,\n",
       " 'filter': 97606,\n",
       " 'autistic': 33855,\n",
       " 'theyre': 250829,\n",
       " 'born': 45979,\n",
       " 'why': 274954,\n",
       " 'scamming': 221218,\n",
       " 'bro': 47962,\n",
       " 'hkms': 121652,\n",
       " 'blatant': 43505,\n",
       " 'troll': 257300,\n",
       " 'answer': 27896,\n",
       " 'obvious': 179990,\n",
       " 'realize': 207782,\n",
       " 'russian': 218046,\n",
       " 'jealous': 134734,\n",
       " 'get': 107760,\n",
       " 'money': 165820,\n",
       " 'ramsay': 205941,\n",
       " 'kill': 140465,\n",
       " 'roose': 216217,\n",
       " 'clearly': 59802,\n",
       " 'going': 110224,\n",
       " 'physically': 192268,\n",
       " 'build': 49334,\n",
       " 'railroad': 205560,\n",
       " 'by': 50970,\n",
       " 'himself': 121029,\n",
       " 'arent': 30629,\n",
       " 'crappy': 67139,\n",
       " 'texture': 249450,\n",
       " 'me': 158974,\n",
       " 'had': 115109,\n",
       " 'go': 109726,\n",
       " 'way': 272156,\n",
       " 'find': 97710,\n",
       " 'them': 250241,\n",
       " 'thought': 251577,\n",
       " 'thai': 249626,\n",
       " 'migrant': 162470,\n",
       " 'worker': 277354,\n",
       " 'scandal': 221231,\n",
       " 'die': 77018,\n",
       " 'hard': 116805,\n",
       " '2': 6044,\n",
       " 'girl': 108757,\n",
       " 'poop': 196057,\n",
       " 'putting': 203090,\n",
       " 'finger': 97793,\n",
       " 'vagina': 266062,\n",
       " 'hell': 119064,\n",
       " 'paul': 188809,\n",
       " 'mcbeth': 158361,\n",
       " 'mike': 162538,\n",
       " 'piazza': 192337,\n",
       " 'chicken': 57263,\n",
       " 'strip': 241141,\n",
       " 'smut': 232828,\n",
       " 'peddler': 189575,\n",
       " 'last': 145167,\n",
       " 'second': 223301,\n",
       " 'video': 268218,\n",
       " 'lost': 151306,\n",
       " 'while': 274311,\n",
       " 'entire': 89019,\n",
       " 'spent': 236365,\n",
       " 'showing': 228537,\n",
       " 'dominating': 80284,\n",
       " 'post': 196763,\n",
       " 'thats': 249854,\n",
       " 'interpretation': 131120,\n",
       " 'hillary': 120848,\n",
       " 'ha': 114847,\n",
       " 'hot': 123374,\n",
       " 'sauce': 220695,\n",
       " 'her': 119456,\n",
       " 'purse': 202896,\n",
       " 'yes': 281322,\n",
       " 'original': 183893,\n",
       " 'movie': 167604,\n",
       " 'certainly': 55441,\n",
       " 'great': 112115,\n",
       " 'example': 91791,\n",
       " 'impressive': 128045,\n",
       " 'dialog': 76602,\n",
       " 'negative': 172325,\n",
       " 'calorie': 51927,\n",
       " 'cancel': 52354,\n",
       " 'positive': 196661,\n",
       " 'essentially': 90336,\n",
       " 'eat': 85051,\n",
       " 'those': 251522,\n",
       " 'fit': 98413,\n",
       " 'fabulous': 93659,\n",
       " 'praise': 197887,\n",
       " 'football': 100311,\n",
       " 'jesus': 135235,\n",
       " 'literally': 149394,\n",
       " 'irony': 132201,\n",
       " 'dare': 71366,\n",
       " 'sexual': 225804,\n",
       " 'she': 226706,\n",
       " 'men': 160386,\n",
       " 'bury': 50081,\n",
       " 'next': 173585,\n",
       " 'koi': 142028,\n",
       " 'pond': 195925,\n",
       " 'satan': 220551,\n",
       " 'sin': 229822,\n",
       " 'duh': 83519,\n",
       " 'isnt': 132683,\n",
       " 'called': 51826,\n",
       " 'egg': 86165,\n",
       " 'loving': 151585,\n",
       " 'effort': 86079,\n",
       " 'message': 160991,\n",
       " 'wanted': 271175,\n",
       " 'popcap': 196166,\n",
       " 'screening': 222542,\n",
       " 'up': 264148,\n",
       " 'thanks': 249693,\n",
       " 'shouldve': 228434,\n",
       " 'pressed': 199090,\n",
       " 'altz': 25647,\n",
       " 'enablesdisables': 88073,\n",
       " 'hud': 124168,\n",
       " 'seattle': 223205,\n",
       " 'graph': 111858,\n",
       " 'lololololol': 150583,\n",
       " 'gain': 104858,\n",
       " 'traction': 255534,\n",
       " 'em': 87466,\n",
       " 'recommending': 208542,\n",
       " 'sometimes': 234466,\n",
       " 'buy': 50779,\n",
       " 'goof': 110731,\n",
       " 'off': 180518,\n",
       " 'thinking': 251093,\n",
       " 'same': 219695,\n",
       " 'thing': 250971,\n",
       " 'realizing': 207791,\n",
       " 'rubbed': 217404,\n",
       " 'paint': 186786,\n",
       " 'normal': 177374,\n",
       " 'subreddit': 242077,\n",
       " 'shout': 228446,\n",
       " 'land': 144630,\n",
       " 'fist': 98384,\n",
       " 'shot': 228303,\n",
       " 'cut': 69785,\n",
       " 'lag': 144232,\n",
       " 'race': 204879,\n",
       " 'home': 122362,\n",
       " 'country': 66402,\n",
       " 'denmark': 74886,\n",
       " 'send': 224727,\n",
       " 'middle': 162133,\n",
       " 'east': 84938,\n",
       " 'somewhere': 234491,\n",
       " 'criminal': 67736,\n",
       " 'intend': 130735,\n",
       " 'harm': 117056,\n",
       " 'black': 43025,\n",
       " 'gun': 113960,\n",
       " 'will': 275445,\n",
       " 'gracefully': 111536,\n",
       " 'turn': 258769,\n",
       " 'too': 254314,\n",
       " 'radwater': 205263,\n",
       " 'from': 102601,\n",
       " 'toilet': 253920,\n",
       " 'foranything': 100408,\n",
       " 'twin': 259247,\n",
       " 'one': 182104,\n",
       " 'cube': 68964,\n",
       " 'edh': 85642,\n",
       " 'deck': 73237,\n",
       " 'sliver': 231891,\n",
       " 'arcane': 30339,\n",
       " 'care': 53243,\n",
       " 'change': 56049,\n",
       " 'where': 274222,\n",
       " 'interrupted': 131151,\n",
       " 'midunhook': 162370,\n",
       " 'superbowl': 243204,\n",
       " 'bound': 46368,\n",
       " 'foursome': 101176,\n",
       " 'threesome': 251831,\n",
       " 'kind': 140699,\n",
       " 'special': 235985,\n",
       " 'german': 107591,\n",
       " 'word': 277240,\n",
       " 'having': 117741,\n",
       " 'preconceived': 198224,\n",
       " 'notion': 177997,\n",
       " 'something': 234395,\n",
       " 'song': 234575,\n",
       " 'unnerving': 263257,\n",
       " 'listen': 149324,\n",
       " 'everywhere': 91452,\n",
       " 'shocker': 227954,\n",
       " 'bible': 41647,\n",
       " 'covered': 66604,\n",
       " 'mark': 156607,\n",
       " 'gender': 107024,\n",
       " 'otherwise': 184444,\n",
       " 'govt': 111350,\n",
       " 'fernwood': 96718,\n",
       " 'door': 80716,\n",
       " 'iraq': 132017,\n",
       " 'team': 247634,\n",
       " 'contractor': 64610,\n",
       " 'damn': 70972,\n",
       " 'charlie': 56392,\n",
       " 'baker': 36380,\n",
       " 'nazi': 171580,\n",
       " 'fat': 95331,\n",
       " 'expected': 92489,\n",
       " '210': 6912,\n",
       " 'gonna': 110544,\n",
       " 'syandana': 245105,\n",
       " 'feel': 96133,\n",
       " 'spending': 236357,\n",
       " 'warframe': 271336,\n",
       " 'regret': 209908,\n",
       " 'supported': 243759,\n",
       " 'quality': 203793,\n",
       " 'artist': 31532,\n",
       " '1000': 853,\n",
       " 'kenny': 139501,\n",
       " 'death': 72734,\n",
       " 'did': 76930,\n",
       " 'jew': 135341,\n",
       " 'hopefully': 122987,\n",
       " 'theyll': 250822,\n",
       " 'grow': 113078,\n",
       " 'smoothly': 232716,\n",
       " 'excited': 91964,\n",
       " 'patient': 188634,\n",
       " '10wpm': 1820,\n",
       " 'worth': 277706,\n",
       " 'lsus': 151967,\n",
       " 'ken': 139423,\n",
       " 'burn': 49944,\n",
       " 'documentary': 79759,\n",
       " 'chaplin': 56204,\n",
       " 'africa': 22355,\n",
       " 'peaceful': 189377,\n",
       " 'paradise': 187622,\n",
       " 'war': 271238,\n",
       " 'killing': 140540,\n",
       " 'european': 90929,\n",
       " 'arrived': 31300,\n",
       " 'kid': 140252,\n",
       " 'almost': 25141,\n",
       " 'got': 111104,\n",
       " 'away': 34654,\n",
       " 'abductor': 19621,\n",
       " 'given': 108932,\n",
       " 'sunday': 242975,\n",
       " 'these': 250723,\n",
       " 'learn': 146105,\n",
       " 'internet': 131030,\n",
       " 'fast': 95250,\n",
       " 'autist': 33854,\n",
       " 'alliance': 24819,\n",
       " 'satisfied': 220623,\n",
       " 'an': 26682,\n",
       " 'american': 26089,\n",
       " 'revolutionary': 212971,\n",
       " 'era': 89617,\n",
       " 'musical': 169291,\n",
       " 'broadway': 48005,\n",
       " 'beginning': 39618,\n",
       " 'conclusion': 63263,\n",
       " 'framework': 101463,\n",
       " 'built': 49396,\n",
       " 'kewl': 139785,\n",
       " 'bull': 49495,\n",
       " 'pit': 193374,\n",
       " 'chuckecheese': 58405,\n",
       " 'rude': 217513,\n",
       " 'gesture': 107753,\n",
       " 'sailor': 219261,\n",
       " 'spying': 237492,\n",
       " 'level': 147432,\n",
       " 'love': 151476,\n",
       " 'come': 62029,\n",
       " 'act': 20929,\n",
       " 'doing': 80081,\n",
       " 'favor': 95614,\n",
       " 'reject': 210238,\n",
       " 'never': 173199,\n",
       " 'old': 181466,\n",
       " 'here': 119517,\n",
       " 'our': 184589,\n",
       " 'player': 194115,\n",
       " 'moving': 167666,\n",
       " 'liverpool': 149604,\n",
       " 'cute': 69797,\n",
       " 'story': 240493,\n",
       " 'cop': 65164,\n",
       " 'kettled': 139735,\n",
       " 'arrest': 31245,\n",
       " 'everyone': 91380,\n",
       " 'liked': 148574,\n",
       " 'john': 136123,\n",
       " 'carter': 53730,\n",
       " 'between': 41223,\n",
       " 'nikkis': 174405,\n",
       " 'thigh': 250934,\n",
       " 'new': 173289,\n",
       " 'electric': 86839,\n",
       " 'razor': 207038,\n",
       " 'walang': 270819,\n",
       " 'manlalaban': 155808,\n",
       " 'd2': 70292,\n",
       " 'dahil': 70653,\n",
       " 'due': 83453,\n",
       " 'process': 200064,\n",
       " 'sila': 229477,\n",
       " 'ex': 91699,\n",
       " 'manipulative': 155763,\n",
       " 'emotionally': 87849,\n",
       " 'abusive': 20183,\n",
       " 'person': 190963,\n",
       " 'sex': 225675,\n",
       " 'totally': 254966,\n",
       " 'surround': 244102,\n",
       " 'advisor': 21920,\n",
       " 'tell': 248435,\n",
       " 'gay': 106332,\n",
       " 'changing': 56102,\n",
       " 'profile': 200333,\n",
       " 'picture': 192512,\n",
       " 'using': 265245,\n",
       " 'hashtag': 117341,\n",
       " 'notppa': 178053,\n",
       " 'difference': 77171,\n",
       " 'berry': 40769,\n",
       " 'raise': 205638,\n",
       " 'stat': 238841,\n",
       " '1': 850,\n",
       " '0': 0,\n",
       " 'substitute1': 242187,\n",
       " 'use': 265050,\n",
       " 'throw': 251950,\n",
       " 'pokemon': 195343,\n",
       " 'sub': 241783,\n",
       " 'appers': 29724,\n",
       " 'switch': 244937,\n",
       " 'gone': 110521,\n",
       " 'psa': 201666,\n",
       " 'meme': 160217,\n",
       " '10': 851,\n",
       " 'year': 280930,\n",
       " 'pnoy': 194924,\n",
       " 'always': 25698,\n",
       " 'graceful': 111534,\n",
       " 'pr': 197796,\n",
       " 'skill': 230809,\n",
       " 'ronda': 216069,\n",
       " 'through': 251931,\n",
       " 'suck': 242391,\n",
       " 'chrome': 58285,\n",
       " 'trailer': 255683,\n",
       " 'hitch': 121455,\n",
       " 'welcome': 273139,\n",
       " 'america': 26065,\n",
       " 'first': 98183,\n",
       " 'haha': 115256,\n",
       " 'wow': 278242,\n",
       " 'obscure': 179878,\n",
       " 'explains': 92655,\n",
       " 'production': 200217,\n",
       " 'job': 135917,\n",
       " 'came': 52024,\n",
       " 'u': 259837,\n",
       " 'union': 262853,\n",
       " 'weaker': 272388,\n",
       " 'beware': 41284,\n",
       " 'jingoistic': 135700,\n",
       " 'chant': 56152,\n",
       " 'perfectly': 190536,\n",
       " 'reasonable': 207975,\n",
       " 'best': 40892,\n",
       " 'scrap': 222435,\n",
       " 'metal': 161122,\n",
       " 'useful': 265076,\n",
       " 'sheet': 226816,\n",
       " 'neuer': 173073,\n",
       " 'midfielder': 162202,\n",
       " 'tho': 251397,\n",
       " 'vaguely': 266103,\n",
       " 'recall': 208226,\n",
       " 'verse': 267698,\n",
       " 'stating': 238989,\n",
       " 'under': 261810,\n",
       " 'duress': 83986,\n",
       " 'commanded': 62213,\n",
       " 'revenge': 212796,\n",
       " 'possible': 196724,\n",
       " 'face': 93674,\n",
       " 'disguise': 78459,\n",
       " 'oh': 180991,\n",
       " 'fan': 94658,\n",
       " 'access': 20358,\n",
       " 'actual': 21085,\n",
       " 'medical': 159441,\n",
       " 'data': 71713,\n",
       " 'chancellor': 56008,\n",
       " 'faking': 94344,\n",
       " 'injury': 129794,\n",
       " 'hurt': 124829,\n",
       " 'ur': 264685,\n",
       " 'man': 155307,\n",
       " 'running': 217857,\n",
       " 'valve': 266348,\n",
       " 'circle': 58829,\n",
       " 'jerking': 135106,\n",
       " 'shes': 227006,\n",
       " 'blind': 43692,\n",
       " 'bag': 36139,\n",
       " 'pop': 196162,\n",
       " 'f2p': 93457,\n",
       " 'pleb': 194445,\n",
       " 'amp': 26472,\n",
       " 'jr': 136716,\n",
       " 'reddits': 208939,\n",
       " 'entertainment': 88978,\n",
       " 'win': 275609,\n",
       " 'cleanly': 59756,\n",
       " 'struggle': 241302,\n",
       " 'smoker': 232663,\n",
       " 'relatable': 210346,\n",
       " 'african': 22361,\n",
       " 'youth': 282210,\n",
       " 'git': 108863,\n",
       " 'gud': 113610,\n",
       " 'v': 265777,\n",
       " 'alright': 25378,\n",
       " 'hellish': 119121,\n",
       " 'park': 187905,\n",
       " 'stadium': 238214,\n",
       " 'gold': 110283,\n",
       " 'routewe': 216713,\n",
       " 'parking': 187933,\n",
       " 'garage': 105795,\n",
       " 'wish': 276147,\n",
       " 'ufc': 260308,\n",
       " 'fighter': 97360,\n",
       " 'helped': 119217,\n",
       " 'invade': 131475,\n",
       " 'foreign': 100552,\n",
       " 'left': 146444,\n",
       " 'spin': 236571,\n",
       " 'republican': 211548,\n",
       " 'riiight': 214131,\n",
       " 'super': 243152,\n",
       " 'elaborate': 86686,\n",
       " 'route': 216701,\n",
       " 'ignorant': 126735,\n",
       " 'dolphin': 80216,\n",
       " 'say': 220940,\n",
       " 'heil': 118914,\n",
       " 'hitler': 121495,\n",
       " 'sentence': 224904,\n",
       " 'spot': 237144,\n",
       " 'wrong': 278591,\n",
       " 'reason': 207973,\n",
       " 'living': 149660,\n",
       " 'nl': 174821,\n",
       " 'since': 229838,\n",
       " '1998': 5487,\n",
       " 'concur': 63297,\n",
       " 'ton': 254200,\n",
       " 'kanyes': 138356,\n",
       " 'track': 255499,\n",
       " 'influential': 129374,\n",
       " 'ironic': 132163,\n",
       " 'interesting': 130895,\n",
       " 'over': 185194,\n",
       " 'voice': 269339,\n",
       " 'opinion': 183153,\n",
       " 'vote': 269756,\n",
       " 'wallet': 270956,\n",
       " 'whats': 274059,\n",
       " 'nipple': 174611,\n",
       " 'absolute': 20067,\n",
       " 'psychopath': 202007,\n",
       " 'allowed': 24969,\n",
       " 'complain': 62796,\n",
       " 'le': 145913,\n",
       " 'fortunate': 100961,\n",
       " 'retrial': 212609,\n",
       " 'sad': 218947,\n",
       " 'surely': 243956,\n",
       " 'fruit': 102840,\n",
       " 'true': 257607,\n",
       " 'church': 58500,\n",
       " 'sticker': 239789,\n",
       " 'mess': 160989,\n",
       " 'stuff': 241477,\n",
       " 'store': 240372,\n",
       " 'especially': 90216,\n",
       " 'thrift': 251865,\n",
       " 'wearin': 272519,\n",
       " 'rep': 211143,\n",
       " 'jeremy': 135079,\n",
       " 'vpn': 269885,\n",
       " 'outside': 185040,\n",
       " 'end': 88219,\n",
       " 'potentially': 197252,\n",
       " 'connected': 63846,\n",
       " 'isp': 132737,\n",
       " 'verizon': 267572,\n",
       " 'throttle': 251925,\n",
       " 'cleartext': 59819,\n",
       " 'traffic': 255632,\n",
       " 'enters': 88969,\n",
       " 'leaf': 145971,\n",
       " 'provider': 201421,\n",
       " 'assumed': 32501,\n",
       " 'grenade': 112441,\n",
       " 'killed': 140500,\n",
       " 'blew': 43666,\n",
       " 'plot': 194614,\n",
       " 'armour': 31049,\n",
       " 'doctor': 79719,\n",
       " 'omh': 181861,\n",
       " 'beat': 38985,\n",
       " 'infiltration': 129285,\n",
       " 'give': 108919,\n",
       " 'veterns': 267877,\n",
       " 'discountsfree': 78263,\n",
       " 'food': 100200,\n",
       " 'service': 225392,\n",
       " 'pay': 188958,\n",
       " 'anyway': 29223,\n",
       " 'cause': 54493,\n",
       " 'tip': 253100,\n",
       " 'stray': 240863,\n",
       " 'anymore': 29125,\n",
       " 'fuck': 103122,\n",
       " 'as': 31657,\n",
       " 'afterlife': 22451,\n",
       " 'system': 245448,\n",
       " 'option': 183457,\n",
       " 'subjugate': 241963,\n",
       " 'myself': 169903,\n",
       " 'capitalist': 52809,\n",
       " 'real': 207699,\n",
       " 'freedom': 101833,\n",
       " 'cept': 55360,\n",
       " 'misandry': 163827,\n",
       " 'third': 251165,\n",
       " 'world': 277497,\n",
       " 'shithole': 227627,\n",
       " 'live': 149554,\n",
       " 'human': 124383,\n",
       " 'ah': 23044,\n",
       " 'rich': 213595,\n",
       " 'rule': 217635,\n",
       " 'apply': 29820,\n",
       " 'ballgame': 36570,\n",
       " 'maggle': 154098,\n",
       " 'dome': 80247,\n",
       " 'flagstaff': 98707,\n",
       " 'lot': 151322,\n",
       " 'editing': 85679,\n",
       " 'crowd': 68299,\n",
       " 'trade': 255548,\n",
       " 'ryan': 218344,\n",
       " 'anderson': 26992,\n",
       " 'ban': 36802,\n",
       " 'rengar': 211002,\n",
       " '14': 3296,\n",
       " 'dropped': 82712,\n",
       " 'dude': 83388,\n",
       " 'nice': 173870,\n",
       " 'legendary': 146608,\n",
       " 'police': 195491,\n",
       " 'snarky': 232974,\n",
       " 'righteous': 213974,\n",
       " 'response': 212144,\n",
       " 'suffered': 242516,\n",
       " 'admitted': 21608,\n",
       " 'mental': 160544,\n",
       " 'hospital': 123315,\n",
       " 'flyer': 99723,\n",
       " 'central': 55272,\n",
       " 'bank': 37048,\n",
       " 'own': 186021,\n",
       " 'api': 29489,\n",
       " 'forward': 100998,\n",
       " 'device': 76154,\n",
       " 'lizard': 149687,\n",
       " 'hide': 120301,\n",
       " 'tail': 246070,\n",
       " 'dirty': 77972,\n",
       " 'fucking': 103227,\n",
       " 'hippy': 121238,\n",
       " 'speed': 236140,\n",
       " 'acceleration': 20302,\n",
       " 'rhodes': 213433,\n",
       " 'flair': 98720,\n",
       " 'tweet': 259130,\n",
       " 'such': 242377,\n",
       " 'kayfabe': 138943,\n",
       " 'city': 59137,\n",
       " 'mountain': 167402,\n",
       " 'behind': 39703,\n",
       " 'saladbarman': 219385,\n",
       " 'likely': 148619,\n",
       " 'bit': 42659,\n",
       " 'cleverer': 59934,\n",
       " 'eto': 90694,\n",
       " 'wont': 276958,\n",
       " 'shirazu': 227464,\n",
       " 'dying': 84415,\n",
       " 'levinci': 147521,\n",
       " 'nba': 171650,\n",
       " 'touch': 255058,\n",
       " 'call': 51809,\n",
       " 'op': 182903,\n",
       " 'faggot': 94062,\n",
       " 'please': 194396,\n",
       " 'edit': 85670,\n",
       " 'theirs': 250189,\n",
       " 'case': 53851,\n",
       " 'receive': 208292,\n",
       " 'watched': 271809,\n",
       " 'episode': 89382,\n",
       " 'questioning': 204173,\n",
       " 'legitimacy': 146702,\n",
       " 'scoop': 222203,\n",
       " 'grey': 112501,\n",
       " 'ogre': 180979,\n",
       " 'white': 274462,\n",
       " 'chick': 57255,\n",
       " 'privilege': 199769,\n",
       " 'different': 77183,\n",
       " 'encryption': 88202,\n",
       " 'algorithm': 24442,\n",
       " 'confiscated': 63589,\n",
       " 'nsa': 178548,\n",
       " 'cia': 58583,\n",
       " 'account': 20466,\n",
       " 'being': 39762,\n",
       " 'advanced': 21812,\n",
       " 'urquharts': 264844,\n",
       " 'government': 111273,\n",
       " 'worse': 277648,\n",
       " 'controversy': 64762,\n",
       " 'bagger': 36166,\n",
       " '288': 8510,\n",
       " 'empire': 87923,\n",
       " 'ticket': 252321,\n",
       " ...}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By using the following dict, we can obtain the index of a given word for querying tfidf matrix.\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b24dd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once we have learned word vectors, to compute the sentence vector of a comment,\n",
    "first fetch the corresponding row from the tfidf matrix (if it is the i-th original comment, then\n",
    "it is the i-th row; if it is the i-th parent comment, then it is the (1010773 + i)-th row),\n",
    "second for each word in the comment find its corresponding tfidf value from the row,\n",
    "third compute the average of the word vectors weighted by corresponding tfidf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fa659c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212926, 284405)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ecb5614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrix[0,249920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5101fd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249854"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['thats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f5a0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfMatrixtest = tfidfVectorizer.transform(pd.concat([X_test['comment_tokens'], X_test['parent_comment_tokens']]))\n",
    "tfidfMatrixvalid = tfidfVectorizer.transform(pd.concat([X_val['comment_tokens'], X_val['parent_comment_tokens']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0327ae83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404310, 284405)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrixtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c6b5aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_tokens</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[knew, it, fuckin, pc, fag, 247, on, pc, and, ...</td>\n",
       "      <td>[the, only, thing, im, heavily, addicted, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[they, say, early, second, or, pile, of, mid, ...</td>\n",
       "      <td>[no, and, the, article, doesnt, say, that, eit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fire, up, the, oven]</td>\n",
       "      <td>[so, what, to, do, eugenics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[lmao]</td>\n",
       "      <td>[risrael, rpalestine, take, note]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rngesus, ha, blessed, you, boi]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[final, fantasy, ex, sound, so, much, cooler, ...</td>\n",
       "      <td>[i, prefer, the, pronunciation, ex, post, soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[yeah, starbound, is, a, dope, simulator]</td>\n",
       "      <td>[so, the, space, exploration, is, too, realist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[yes, because, american, historically, lack, t...</td>\n",
       "      <td>[yeah, but, you, guy, get, vacation, and, trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[it, irrational, and, allows, men, to, be, led...</td>\n",
       "      <td>[nationalism, is, badwhy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[so, similar, to, wine, on, linux]</td>\n",
       "      <td>[it, actually, different, an, emulator, is, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_tokens  \\\n",
       "0  [knew, it, fuckin, pc, fag, 247, on, pc, and, ...   \n",
       "1  [they, say, early, second, or, pile, of, mid, ...   \n",
       "2                              [fire, up, the, oven]   \n",
       "3                                             [lmao]   \n",
       "4                   [rngesus, ha, blessed, you, boi]   \n",
       "5  [final, fantasy, ex, sound, so, much, cooler, ...   \n",
       "6          [yeah, starbound, is, a, dope, simulator]   \n",
       "7  [yes, because, american, historically, lack, t...   \n",
       "8  [it, irrational, and, allows, men, to, be, led...   \n",
       "9                 [so, similar, to, wine, on, linux]   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [the, only, thing, im, heavily, addicted, to, ...  \n",
       "1  [no, and, the, article, doesnt, say, that, eit...  \n",
       "2                       [so, what, to, do, eugenics]  \n",
       "3                  [risrael, rpalestine, take, note]  \n",
       "4                                               [10]  \n",
       "5  [i, prefer, the, pronunciation, ex, post, soun...  \n",
       "6  [so, the, space, exploration, is, too, realist...  \n",
       "7  [yeah, but, you, guy, get, vacation, and, trav...  \n",
       "8                          [nationalism, is, badwhy]  \n",
       "9  [it, actually, different, an, emulator, is, a,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "433cb335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100394"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['for']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a709bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrixtest[0, 100573]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "894f6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(X, tfidfmat):\n",
    "    comment_featurevec = []\n",
    "    parent_featurevec = []\n",
    "    \n",
    "    for index, sample in X.iterrows():\n",
    "        \n",
    "        comment_vec = np.zeros(300)\n",
    "        parent_comment_vec = np.zeros(300)\n",
    "        comment_tokens = sample['comment_tokens']\n",
    "        parent_comment_tokens = sample['parent_comment_tokens']\n",
    "        counter1 = 0\n",
    "        \n",
    "        for token in comment_tokens:\n",
    "            \n",
    "            if token in glove and token in vocabulary:\n",
    "                counter1 += 1\n",
    "                comment_vec += tfidfmat[index, vocabulary[token]] * glove[token]\n",
    "        \n",
    "        counter2 = 0\n",
    "        for token in parent_comment_tokens:\n",
    "            \n",
    "            if token in glove and token in vocabulary:\n",
    "                counter2 += 1 \n",
    "                parent_comment_vec += tfidfmat[index+len(X), vocabulary[token]] * glove[token]\n",
    "        \n",
    "        if counter1 != 0:\n",
    "            comment_featurevec.append(comment_vec/counter1)\n",
    "        else:\n",
    "            comment_featurevec.append(comment_vec)\n",
    "        \n",
    "        if counter2 != 0:\n",
    "            parent_featurevec.append(parent_comment_vec/counter2)\n",
    "        else:\n",
    "            parent_featurevec.append(parent_comment_vec)\n",
    "            \n",
    "        \n",
    "    #print(len(comment_featurevec))\n",
    "    X['comment_weighted_vec'] = comment_featurevec\n",
    "    X['parent_weighted_vec'] = parent_featurevec\n",
    "    new_df = pd.DataFrame()\n",
    "        \n",
    "    return X\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "605e9ced",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (599058) does not match length of index (606463)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20168/2805482821.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidfMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20168/1500059477.py\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[1;34m(X, tfidfmat)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#print(len(comment_featurevec))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment_weighted_vec'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomment_featurevec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'parent_weighted_vec'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_featurevec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (599058) does not match length of index (606463)"
     ]
    }
   ],
   "source": [
    "X_train = generate_dataset(X_train, tfidfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = generate_dataset(X_val, tfidfMatrixval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4be4f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = generate_dataset(X_test, tfidfMatrixtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14178717",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['comment_weighted_vec', 'parent_weighted_vec']]\n",
    "X_val = X_val[['comment_weighted_vec', 'parent_weighted_vec']]\n",
    "X_test = X_test[['comment_weighted_vec', 'parent_weighted_vec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48c7cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(dataset):\n",
    "    x = pd.DataFrame(dataset['parent_weighted_vec'].tolist(), columns = [i for i in range(300)])\n",
    "    y = pd.DataFrame(dataset['comment_weighted_vec'].tolist(), columns = [i for i in range(300, 600)])\n",
    "    return pd.concat([x, y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4924e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = featurize(X_train)\n",
    "X_val = featurize(X_val)\n",
    "X_test = featurize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f4c4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=0).fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d33ffce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f9d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81437f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e2ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9c63624",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83ff02",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd2d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
