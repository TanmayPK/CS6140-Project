{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6140 Project - Detection Of Sarcasm In Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if running notebook with vectors locally for first time. Files added to gitignore\n",
    "# glove = api.load('glove-wiki-gigaword-300')\n",
    "# glove.save('glovevectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load('glovevectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these if not up to date\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['label', 'comment', 'subreddit', 'score', 'parent_comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't pay attention to her, but as long as s...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0</td>\n",
       "      <td>do you find ariana grande sexy ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Trick or treating in general is just weird...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1</td>\n",
       "      <td>What's your weird or unsettling Trick or Treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Blade Mastery+Masamune or GTFO!</td>\n",
       "      <td>FFBraveExvius</td>\n",
       "      <td>2</td>\n",
       "      <td>Probably Sephiroth. I refuse to taint his grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>You don't have to, you have a good build, buy ...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>1</td>\n",
       "      <td>What to upgrade? I have $500 to spend (mainly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>I would love to see him at lolla.</td>\n",
       "      <td>Lollapalooza</td>\n",
       "      <td>2</td>\n",
       "      <td>Probably count Kanye out Since the rest of his...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0                                         NC and NH.   \n",
       "1      0  You do know west teams play against west teams...   \n",
       "2      0  They were underdogs earlier today, but since G...   \n",
       "3      0  This meme isn't funny none of the \"new york ni...   \n",
       "4      0                    I could use one of those tools.   \n",
       "5      0  I don't pay attention to her, but as long as s...   \n",
       "6      0      Trick or treating in general is just weird...   \n",
       "7      0                    Blade Mastery+Masamune or GTFO!   \n",
       "8      0  You don't have to, you have a good build, buy ...   \n",
       "9      0                  I would love to see him at lolla.   \n",
       "\n",
       "            subreddit  score  \\\n",
       "0            politics      2   \n",
       "1                 nba     -4   \n",
       "2                 nfl      3   \n",
       "3  BlackPeopleTwitter     -8   \n",
       "4  MaddenUltimateTeam      6   \n",
       "5           AskReddit      0   \n",
       "6           AskReddit      1   \n",
       "7       FFBraveExvius      2   \n",
       "8        pcmasterrace      1   \n",
       "9        Lollapalooza      2   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  \n",
       "5                   do you find ariana grande sexy ?  \n",
       "6  What's your weird or unsettling Trick or Treat...  \n",
       "7  Probably Sephiroth. I refuse to taint his grea...  \n",
       "8  What to upgrade? I have $500 to spend (mainly ...  \n",
       "9  Probably count Kanye out Since the rest of his...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label              0\n",
       "comment           53\n",
       "subreddit          0\n",
       "score              0\n",
       "parent_comment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label             0\n",
       "comment           0\n",
       "subreddit         0\n",
       "score             0\n",
       "parent_comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment_tokens'] = data['comment']\n",
    "data['comment_tokens'] = data['comment_tokens'].str.lower()\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('can\\'t','can not',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('\\'d',' would',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('wouldn\\'t','would not',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('couldn\\'t','could not',regex = True)\n",
    "data['comment_tokens'] = data['comment_tokens'].str.replace('[^\\w\\s]','', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['parent_comment_tokens'] = data['parent_comment']\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.lower()\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('can\\'t','can not',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('\\'d',' would',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('wouldn\\'t','would not',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('couldn\\'t','could not',regex = True)\n",
    "data['parent_comment_tokens'] = data['parent_comment_tokens'].str.replace('[^\\w\\s]','', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "def apply_lemmatizer(sentence):\n",
    "    return [lemma.lemmatize(token) for token in wordpunct_tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"comment_tokens\"] = data.comment_tokens.apply(apply_lemmatizer)\n",
    "data[\"parent_comment_tokens\"] = data.parent_comment_tokens.apply(apply_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>[nc, and, nh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>[you, do, know, west, team, play, against, wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>[they, were, underdog, earlier, today, but, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>[this, meme, isnt, funny, none, of, the, new, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>[i, could, use, one, of, those, tool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I don't pay attention to her, but as long as s...</td>\n",
       "      <td>[i, dont, pay, attention, to, her, but, a, lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trick or treating in general is just weird...</td>\n",
       "      <td>[trick, or, treating, in, general, is, just, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blade Mastery+Masamune or GTFO!</td>\n",
       "      <td>[blade, masterymasamune, or, gtfo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You don't have to, you have a good build, buy ...</td>\n",
       "      <td>[you, dont, have, to, you, have, a, good, buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I would love to see him at lolla.</td>\n",
       "      <td>[i, would, love, to, see, him, at, lolla]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0                                         NC and NH.   \n",
       "1  You do know west teams play against west teams...   \n",
       "2  They were underdogs earlier today, but since G...   \n",
       "3  This meme isn't funny none of the \"new york ni...   \n",
       "4                    I could use one of those tools.   \n",
       "5  I don't pay attention to her, but as long as s...   \n",
       "6      Trick or treating in general is just weird...   \n",
       "7                    Blade Mastery+Masamune or GTFO!   \n",
       "8  You don't have to, you have a good build, buy ...   \n",
       "9                  I would love to see him at lolla.   \n",
       "\n",
       "                                      comment_tokens  \n",
       "0                                      [nc, and, nh]  \n",
       "1  [you, do, know, west, team, play, against, wes...  \n",
       "2  [they, were, underdog, earlier, today, but, si...  \n",
       "3  [this, meme, isnt, funny, none, of, the, new, ...  \n",
       "4              [i, could, use, one, of, those, tool]  \n",
       "5  [i, dont, pay, attention, to, her, but, a, lon...  \n",
       "6  [trick, or, treating, in, general, is, just, w...  \n",
       "7                 [blade, masterymasamune, or, gtfo]  \n",
       "8  [you, dont, have, to, you, have, a, good, buil...  \n",
       "9          [i, would, love, to, see, him, at, lolla]  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"comment\", \"comment_tokens\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>[yeah, i, get, that, argument, at, this, point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>[the, blazer, and, maverick, the, west, 5, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>[theyre, favored, to, win]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "      <td>[deadass, dont, kill, my, buzz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "      <td>[yep, can, confirm, i, saw, the, tool, they, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>do you find ariana grande sexy ?</td>\n",
       "      <td>[do, you, find, ariana, grande, sexy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What's your weird or unsettling Trick or Treat...</td>\n",
       "      <td>[whats, your, weird, or, unsettling, trick, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Probably Sephiroth. I refuse to taint his grea...</td>\n",
       "      <td>[probably, sephiroth, i, refuse, to, taint, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What to upgrade? I have $500 to spend (mainly ...</td>\n",
       "      <td>[what, to, upgrade, i, have, 500, to, spend, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Probably count Kanye out Since the rest of his...</td>\n",
       "      <td>[probably, count, kanye, out, since, the, rest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      parent_comment  \\\n",
       "0  Yeah, I get that argument. At this point, I'd ...   \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...   \n",
       "2                            They're favored to win.   \n",
       "3                         deadass don't kill my buzz   \n",
       "4  Yep can confirm I saw the tool they use for th...   \n",
       "5                   do you find ariana grande sexy ?   \n",
       "6  What's your weird or unsettling Trick or Treat...   \n",
       "7  Probably Sephiroth. I refuse to taint his grea...   \n",
       "8  What to upgrade? I have $500 to spend (mainly ...   \n",
       "9  Probably count Kanye out Since the rest of his...   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [yeah, i, get, that, argument, at, this, point...  \n",
       "1  [the, blazer, and, maverick, the, west, 5, and...  \n",
       "2                         [theyre, favored, to, win]  \n",
       "3                    [deadass, dont, kill, my, buzz]  \n",
       "4  [yep, can, confirm, i, saw, the, tool, they, u...  \n",
       "5              [do, you, find, ariana, grande, sexy]  \n",
       "6  [whats, your, weird, or, unsettling, trick, or...  \n",
       "7  [probably, sephiroth, i, refuse, to, taint, hi...  \n",
       "8  [what, to, upgrade, i, have, 500, to, spend, m...  \n",
       "9  [probably, count, kanye, out, since, the, rest...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"parent_comment\", \"parent_comment_tokens\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['parent_comment_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['comment_tokens', 'parent_comment_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_tokens</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nc, and, nh]</td>\n",
       "      <td>[yeah, i, get, that, argument, at, this, point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[you, do, know, west, team, play, against, wes...</td>\n",
       "      <td>[the, blazer, and, maverick, the, west, 5, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[they, were, underdog, earlier, today, but, si...</td>\n",
       "      <td>[theyre, favored, to, win]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[this, meme, isnt, funny, none, of, the, new, ...</td>\n",
       "      <td>[deadass, dont, kill, my, buzz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, could, use, one, of, those, tool]</td>\n",
       "      <td>[yep, can, confirm, i, saw, the, tool, they, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[i, dont, pay, attention, to, her, but, a, lon...</td>\n",
       "      <td>[do, you, find, ariana, grande, sexy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[trick, or, treating, in, general, is, just, w...</td>\n",
       "      <td>[whats, your, weird, or, unsettling, trick, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[blade, masterymasamune, or, gtfo]</td>\n",
       "      <td>[probably, sephiroth, i, refuse, to, taint, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[you, dont, have, to, you, have, a, good, buil...</td>\n",
       "      <td>[what, to, upgrade, i, have, 500, to, spend, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[i, would, love, to, see, him, at, lolla]</td>\n",
       "      <td>[probably, count, kanye, out, since, the, rest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_tokens  \\\n",
       "0                                      [nc, and, nh]   \n",
       "1  [you, do, know, west, team, play, against, wes...   \n",
       "2  [they, were, underdog, earlier, today, but, si...   \n",
       "3  [this, meme, isnt, funny, none, of, the, new, ...   \n",
       "4              [i, could, use, one, of, those, tool]   \n",
       "5  [i, dont, pay, attention, to, her, but, a, lon...   \n",
       "6  [trick, or, treating, in, general, is, just, w...   \n",
       "7                 [blade, masterymasamune, or, gtfo]   \n",
       "8  [you, dont, have, to, you, have, a, good, buil...   \n",
       "9          [i, would, love, to, see, him, at, lolla]   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [yeah, i, get, that, argument, at, this, point...  \n",
       "1  [the, blazer, and, maverick, the, west, 5, and...  \n",
       "2                         [theyre, favored, to, win]  \n",
       "3                    [deadass, dont, kill, my, buzz]  \n",
       "4  [yep, can, confirm, i, saw, the, tool, they, u...  \n",
       "5              [do, you, find, ariana, grande, sexy]  \n",
       "6  [whats, your, weird, or, unsettling, trick, or...  \n",
       "7  [probably, sephiroth, i, refuse, to, taint, hi...  \n",
       "8  [what, to, upgrade, i, have, 500, to, spend, m...  \n",
       "9  [probably, count, kanye, out, since, the, rest...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010816</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010818</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010819</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010820</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label\n",
       "1010816      1\n",
       "1010817      1\n",
       "1010818      1\n",
       "1010819      1\n",
       "1010820      1\n",
       "1010821      1\n",
       "1010822      1\n",
       "1010823      1\n",
       "1010824      1\n",
       "1010825      1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, train_size= 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, train_size = 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "X_val = X_val.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop = True)\n",
    "y_val = y_val.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_tokens</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[imagine, what, it, like, to, live, with, this...</td>\n",
       "      <td>[so, what, im, reading, here, is, it, your, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a, for, that, second, question, outdoor, adve...</td>\n",
       "      <td>[film, culture, at, uc, davis, im, proud, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[oohhhh, thankfully, he, made, the, comment, a...</td>\n",
       "      <td>[it, a, joke, you, sanctimonious, dickbag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[because, that, like, would, not, be, inclusiv...</td>\n",
       "      <td>[they, wanted, to, tackle, too, many, differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[trying, to, top, the, blink, tour, lineup]</td>\n",
       "      <td>[the, wonder, year, fall, tour, soupy, hinted,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[they, were, drinking, and, fucking, more, tha...</td>\n",
       "      <td>[til, study, show, that, teen, overestimate, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[and, optimism]</td>\n",
       "      <td>[oh, then, todd, is, the, patron, saint, of, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[they, are, white, hispanic, they, dont, count]</td>\n",
       "      <td>[actually, it, primarily, immigrant, only, spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[i, like, how, the, previous, poster, decides,...</td>\n",
       "      <td>[i, wa, at, the, party, but, youre, right, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[that, would, be, considered, a, jamming, devi...</td>\n",
       "      <td>[i, wa, thinking, of, building, a, wifi, ardui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_tokens  \\\n",
       "0  [imagine, what, it, like, to, live, with, this...   \n",
       "1  [a, for, that, second, question, outdoor, adve...   \n",
       "2  [oohhhh, thankfully, he, made, the, comment, a...   \n",
       "3  [because, that, like, would, not, be, inclusiv...   \n",
       "4        [trying, to, top, the, blink, tour, lineup]   \n",
       "5  [they, were, drinking, and, fucking, more, tha...   \n",
       "6                                    [and, optimism]   \n",
       "7    [they, are, white, hispanic, they, dont, count]   \n",
       "8  [i, like, how, the, previous, poster, decides,...   \n",
       "9  [that, would, be, considered, a, jamming, devi...   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [so, what, im, reading, here, is, it, your, fa...  \n",
       "1  [film, culture, at, uc, davis, im, proud, to, ...  \n",
       "2         [it, a, joke, you, sanctimonious, dickbag]  \n",
       "3  [they, wanted, to, tackle, too, many, differen...  \n",
       "4  [the, wonder, year, fall, tour, soupy, hinted,...  \n",
       "5  [til, study, show, that, teen, overestimate, h...  \n",
       "6  [oh, then, todd, is, the, patron, saint, of, d...  \n",
       "7  [actually, it, primarily, immigrant, only, spe...  \n",
       "8  [i, wa, at, the, party, but, youre, right, i, ...  \n",
       "9  [i, wa, thinking, of, building, a, wifi, ardui...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606463"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773, 7)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Since comments are already preprocessed and tokenized,\n",
    "# the vectorizer only needs to take tokens as they are.\n",
    "tfidfVectorizer = TfidfVectorizer(analyzer=lambda tokens: tokens)\n",
    "corpus = pd.concat([X_train['comment_tokens'], X_train['parent_comment_tokens']])\n",
    "tfidfMatrix = tfidfVectorizer.fit_transform(corpus)\n",
    "vocabulary = tfidfVectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212926, 284779)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1212926x284779 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17857503 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the tfidf matrix has 2021546 rows,\n",
    "# where the 0 ~ 606462 rows represent original comments in the same order as those in dataset,\n",
    "# and the 606463 ~ 1212926 rows represent parent comments in the same order as those in dataset;\n",
    "# and the tfidf matrix has 395961 columns, each represents a word in the vocabulary.\n",
    "tfidfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imagine': 128065,\n",
       " 'what': 274367,\n",
       " 'it': 133638,\n",
       " 'like': 149272,\n",
       " 'to': 254036,\n",
       " 'live': 150285,\n",
       " 'with': 276621,\n",
       " 'this': 251665,\n",
       " 'curse': 70236,\n",
       " 'a': 19269,\n",
       " 'for': 101035,\n",
       " 'that': 250264,\n",
       " 'second': 223826,\n",
       " 'question': 204723,\n",
       " 'outdoor': 185259,\n",
       " 'adventure': 22243,\n",
       " 'doe': 80379,\n",
       " 'summer': 243442,\n",
       " 'hike': 121500,\n",
       " 'but': 50969,\n",
       " 'each': 85170,\n",
       " 'one': 182651,\n",
       " 'cost': 66603,\n",
       " 'money': 166523,\n",
       " 'oohhhh': 183260,\n",
       " 'thankfully': 250198,\n",
       " 'he': 118847,\n",
       " 'made': 154486,\n",
       " 'the': 250495,\n",
       " 'comment': 62991,\n",
       " 'and': 27276,\n",
       " 'not': 178235,\n",
       " 'me': 159606,\n",
       " 'i': 126295,\n",
       " 'thought': 251998,\n",
       " 'artist': 31902,\n",
       " 'wa': 270761,\n",
       " 'making': 155405,\n",
       " 'point': 195712,\n",
       " 'about': 20302,\n",
       " 'human': 125089,\n",
       " 'relationship': 210861,\n",
       " 'desire': 76175,\n",
       " 'be': 39263,\n",
       " 'pleasured': 194993,\n",
       " 'because': 39613,\n",
       " 'would': 278089,\n",
       " 'inclusive': 129214,\n",
       " 'man': 155927,\n",
       " 'trying': 258413,\n",
       " 'top': 254929,\n",
       " 'blink': 44289,\n",
       " 'tour': 255582,\n",
       " 'lineup': 149710,\n",
       " 'they': 251244,\n",
       " 'were': 273915,\n",
       " 'drinking': 82935,\n",
       " 'fucking': 103849,\n",
       " 'more': 167372,\n",
       " 'than': 250172,\n",
       " 'so': 234019,\n",
       " 'thats': 250360,\n",
       " 'all': 25010,\n",
       " 'need': 172750,\n",
       " 'know': 142443,\n",
       " 'optimism': 183999,\n",
       " 'are': 30884,\n",
       " 'white': 274865,\n",
       " 'hispanic': 122092,\n",
       " 'dont': 81057,\n",
       " 'count': 66876,\n",
       " 'how': 124441,\n",
       " 'previous': 199867,\n",
       " 'poster': 197426,\n",
       " 'decides': 73726,\n",
       " 'suddenly': 243038,\n",
       " 'stop': 240857,\n",
       " 'responding': 212569,\n",
       " 'once': 182576,\n",
       " 'youve': 282621,\n",
       " 'clear': 60473,\n",
       " 'she': 227257,\n",
       " 'also': 25806,\n",
       " 'flirting': 99963,\n",
       " 'damn': 71543,\n",
       " 'woman': 277098,\n",
       " 'can': 52948,\n",
       " 'ever': 91725,\n",
       " 'do': 80157,\n",
       " 'anything': 29519,\n",
       " 'wrong': 278886,\n",
       " 'by': 51680,\n",
       " 'misinterpreting': 164716,\n",
       " 'action': 21339,\n",
       " 'considered': 64797,\n",
       " 'jamming': 134884,\n",
       " 'device': 76737,\n",
       " 'which': 274696,\n",
       " 'is': 133018,\n",
       " 'illegal': 127784,\n",
       " 'under': 262283,\n",
       " 'industry': 129749,\n",
       " 'canada': 52959,\n",
       " 'regulation': 210454,\n",
       " 'panda': 187769,\n",
       " 'milkshake': 163471,\n",
       " 'through': 252346,\n",
       " 'bamboo': 37255,\n",
       " 'straw': 241426,\n",
       " 'almost': 25535,\n",
       " 'good': 111350,\n",
       " 'thing': 251405,\n",
       " 'doesnt': 80417,\n",
       " 'really': 208312,\n",
       " 'happen': 117325,\n",
       " 'my': 170429,\n",
       " 'reply': 211809,\n",
       " 'you': 282285,\n",
       " 'arent': 30976,\n",
       " 'showing': 229088,\n",
       " 'up': 264625,\n",
       " 'though': 251971,\n",
       " 'plot': 195180,\n",
       " 'twist': 259757,\n",
       " 'ops': 183937,\n",
       " 'looking': 151643,\n",
       " 'new': 173885,\n",
       " 'target': 247397,\n",
       " 'ellaria': 87723,\n",
       " 'girl': 109499,\n",
       " 'actually': 21484,\n",
       " 'bad': 36385,\n",
       " 'actress': 21459,\n",
       " 'well': 273564,\n",
       " 'considering': 64800,\n",
       " '1946postwwiithere': 5424,\n",
       " 'no': 175528,\n",
       " 'threat': 252167,\n",
       " 'on': 182533,\n",
       " 'u': 260278,\n",
       " 'mainland': 155152,\n",
       " 'until': 264405,\n",
       " 'cold': 62158,\n",
       " 'war': 271672,\n",
       " 'ramped': 206441,\n",
       " 'quebec': 204559,\n",
       " 'now': 178841,\n",
       " 'oh': 181512,\n",
       " 'god': 110640,\n",
       " 'played': 194662,\n",
       " 'mortal': 167639,\n",
       " 'kombat': 142859,\n",
       " 'last': 145915,\n",
       " 'night': 174786,\n",
       " 'fight': 97960,\n",
       " 'shit': 228097,\n",
       " 'could': 66817,\n",
       " 'getting': 108568,\n",
       " 'his': 122059,\n",
       " 'm': 153737,\n",
       " 'mean': 159671,\n",
       " 'only': 183038,\n",
       " 'huracan': 125464,\n",
       " 'since': 230407,\n",
       " 'didnt': 77604,\n",
       " 'agree': 23316,\n",
       " 'original': 184437,\n",
       " 'had': 115815,\n",
       " 'use': 265565,\n",
       " 'an': 27031,\n",
       " 'analogy': 27099,\n",
       " 'disagreeing': 78627,\n",
       " 'person': 191553,\n",
       " 'working': 277715,\n",
       " 'keep': 139873,\n",
       " 'alive': 24976,\n",
       " 'forgot': 101358,\n",
       " 'sorry': 235526,\n",
       " 'feel': 96746,\n",
       " 'idiot': 127064,\n",
       " 'expecting': 93048,\n",
       " 'of': 180986,\n",
       " 'just': 137970,\n",
       " 'two': 259849,\n",
       " 'undefeated': 262270,\n",
       " 'team': 248140,\n",
       " 'in': 128874,\n",
       " 'country': 67046,\n",
       " 'yeah': 281163,\n",
       " 'overranked': 186194,\n",
       " 'sure': 244472,\n",
       " 'don': 80869,\n",
       " 'pretty': 199794,\n",
       " 'book': 46068,\n",
       " 'boxer': 47111,\n",
       " 'brief': 48313,\n",
       " 'swimwear': 245369,\n",
       " 'if': 127250,\n",
       " 'daryl': 72223,\n",
       " 'went': 273876,\n",
       " 'out': 185175,\n",
       " 'then': 250845,\n",
       " 'carol': 54158,\n",
       " 'probably': 200446,\n",
       " 'take': 246673,\n",
       " 'maggies': 154738,\n",
       " 'place': 194218,\n",
       " '16': 4228,\n",
       " 'gb': 107190,\n",
       " 'tablet': 246293,\n",
       " '1': 899,\n",
       " 'left': 147207,\n",
       " 'user': 265629,\n",
       " 'storage': 240937,\n",
       " 'after': 22816,\n",
       " 'touchwiz': 255532,\n",
       " 'installation': 131090,\n",
       " 'completely': 63568,\n",
       " 'plausible': 194613,\n",
       " 'cause': 55143,\n",
       " 'kill': 141168,\n",
       " 'baby': 35920,\n",
       " 'even': 91655,\n",
       " 'something': 234977,\n",
       " 'snorlax': 233829,\n",
       " 'or': 184085,\n",
       " 'lapras': 145685,\n",
       " 'ton': 254629,\n",
       " 'candy': 53136,\n",
       " 'powerup': 198177,\n",
       " 'worthwhile': 278044,\n",
       " 'dropped': 83200,\n",
       " 'at': 33130,\n",
       " 'rate': 207161,\n",
       " 'we': 272776,\n",
       " 'might': 163118,\n",
       " 'run': 218221,\n",
       " 'magnet': 154864,\n",
       " 'happened': 117336,\n",
       " 'real': 208195,\n",
       " 'smoking': 233248,\n",
       " 'gun': 114676,\n",
       " 'intentionally': 131469,\n",
       " 'describing': 76032,\n",
       " 'brown': 49063,\n",
       " 'consider': 64784,\n",
       " 'some': 234885,\n",
       " 'your': 282470,\n",
       " 'knife': 142295,\n",
       " 'defense': 74285,\n",
       " 'skill': 231373,\n",
       " 'been': 39895,\n",
       " 'doing': 80608,\n",
       " 'better': 41607,\n",
       " 'recently': 208791,\n",
       " 'wonder': 277232,\n",
       " 'fuck': 103753,\n",
       " 'military': 163406,\n",
       " 'got': 111870,\n",
       " 'without': 276686,\n",
       " 'long': 151424,\n",
       " 'ba': 35783,\n",
       " 'rutten': 218628,\n",
       " 'street': 241545,\n",
       " 'art': 31757,\n",
       " 'deep': 74085,\n",
       " 'must': 170093,\n",
       " 'banksy': 37571,\n",
       " 'dad': 71063,\n",
       " 'say': 221456,\n",
       " 'same': 220178,\n",
       " 'instead': 131168,\n",
       " 'dog': 80451,\n",
       " 'people': 190786,\n",
       " 'cant': 53307,\n",
       " 'discriminated': 78894,\n",
       " 'when': 274605,\n",
       " 'royal': 217238,\n",
       " 'visiting': 269387,\n",
       " 'house': 124308,\n",
       " 'veteran': 268330,\n",
       " 'should': 228940,\n",
       " 'able': 20193,\n",
       " 'get': 108464,\n",
       " 'hardware': 117696,\n",
       " 'right': 214387,\n",
       " 'come': 62757,\n",
       " 'unless': 263537,\n",
       " 'delayed': 74747,\n",
       " 'p': 186754,\n",
       " 'havent': 118424,\n",
       " 'yet': 281787,\n",
       " 'figured': 98033,\n",
       " 'sometimes': 235036,\n",
       " 'hate': 118180,\n",
       " 'anybody': 29435,\n",
       " 'internet': 131731,\n",
       " 'shes': 227574,\n",
       " 'support': 244300,\n",
       " 'meant': 159746,\n",
       " 'burst': 50745,\n",
       " 'mage': 154700,\n",
       " 'lich': 148775,\n",
       " 'bane': 37431,\n",
       " 'here': 120266,\n",
       " 'am': 26123,\n",
       " 'still': 240479,\n",
       " 'figuring': 98043,\n",
       " 'game': 105800,\n",
       " 'uninstall': 263263,\n",
       " 'movie': 168284,\n",
       " 'delete': 74784,\n",
       " 'reminds': 211278,\n",
       " 'saying': 221499,\n",
       " 'piss': 193850,\n",
       " 'tell': 248936,\n",
       " 'raining': 206135,\n",
       " 'going': 110971,\n",
       " 'sound': 235754,\n",
       " 'coming': 62906,\n",
       " 'laptop': 145698,\n",
       " 'speaker': 236510,\n",
       " 'have': 118387,\n",
       " 'ridiculous': 214240,\n",
       " 'bush': 50797,\n",
       " 'thanks': 250205,\n",
       " 'sharing': 227052,\n",
       " 'yes': 281684,\n",
       " 'wb': 272693,\n",
       " 'fox': 101876,\n",
       " 'definetly': 74387,\n",
       " 'pay': 189532,\n",
       " 'off': 181027,\n",
       " 'yt': 282701,\n",
       " 'reviewer': 213319,\n",
       " 'affect': 22562,\n",
       " 'rt': 217652,\n",
       " 'score': 222778,\n",
       " 'gonna': 111309,\n",
       " 'creepy': 68125,\n",
       " 'read': 208077,\n",
       " 'started': 239328,\n",
       " 'seeing': 224151,\n",
       " 'fact': 94479,\n",
       " 'tils': 253038,\n",
       " 'downvoted': 82129,\n",
       " 'them': 250718,\n",
       " 'violent': 269185,\n",
       " 'scum': 223332,\n",
       " 'beat': 39457,\n",
       " 'tesla': 249681,\n",
       " '3000': 9439,\n",
       " 'year': 281304,\n",
       " 'lieill': 148882,\n",
       " 'little': 150216,\n",
       " 'disappointed': 78659,\n",
       " 'there': 251029,\n",
       " 'lightsaber': 149187,\n",
       " 'wielding': 275562,\n",
       " 'jarjar': 135091,\n",
       " 'sighting': 229872,\n",
       " 'world': 277820,\n",
       " 'where': 274628,\n",
       " 'advantageous': 22230,\n",
       " 'chronic': 59013,\n",
       " 'nailbiter': 171110,\n",
       " 'much': 168932,\n",
       " 'nail': 171109,\n",
       " 'dirt': 78539,\n",
       " 'underneath': 262432,\n",
       " 'obviously': 180516,\n",
       " 'never': 173797,\n",
       " 'future': 104857,\n",
       " 'soldier': 234664,\n",
       " 'training': 256174,\n",
       " 'schumers': 222472,\n",
       " 'integrity': 131372,\n",
       " 'wont': 277303,\n",
       " 'shift': 227704,\n",
       " 'political': 196144,\n",
       " 'wind': 276058,\n",
       " 'nope': 177800,\n",
       " 'penis': 190602,\n",
       " 'hard': 117512,\n",
       " 'therefore': 251054,\n",
       " 'consenting': 64709,\n",
       " 'else': 87862,\n",
       " 'remain': 211164,\n",
       " 'happy': 117404,\n",
       " 'shut': 229436,\n",
       " 'mayo': 158765,\n",
       " 'higuain': 121439,\n",
       " 'miss': 164833,\n",
       " 'penalty': 190507,\n",
       " 'either': 87069,\n",
       " 'racist': 205562,\n",
       " 'make': 155330,\n",
       " 'best': 41353,\n",
       " 'cop': 65821,\n",
       " 'nothing': 178450,\n",
       " 'except': 92429,\n",
       " 'police': 196039,\n",
       " 'procedure': 200586,\n",
       " 'paperwork': 188125,\n",
       " 'order': 184219,\n",
       " 'from': 103256,\n",
       " 'higherups': 121223,\n",
       " 'death': 73318,\n",
       " 'dismemberment': 79188,\n",
       " 'will': 275874,\n",
       " 'ftfy': 103662,\n",
       " 'uh': 260887,\n",
       " 'current': 70185,\n",
       " 'ceo': 55977,\n",
       " 'cart': 54347,\n",
       " 'pusher': 203509,\n",
       " 'dentist': 75528,\n",
       " 'trip': 257487,\n",
       " 'freelancer': 102579,\n",
       " 'hesitation': 120625,\n",
       " 'dayz': 72740,\n",
       " 'ha': 115558,\n",
       " 'colour': 62575,\n",
       " 'enjoy': 89185,\n",
       " 'googled': 111538,\n",
       " 'surprise': 244590,\n",
       " 'someone': 234930,\n",
       " 'won': 277227,\n",
       " 'challenge': 56510,\n",
       " 'again': 22924,\n",
       " 'x': 279497,\n",
       " 'stand': 239025,\n",
       " 'xbox': 279741,\n",
       " 'rule': 218119,\n",
       " 'engage': 89007,\n",
       " '2': 6243,\n",
       " 'away': 35085,\n",
       " 'show': 229023,\n",
       " 'rear': 208431,\n",
       " 'armor': 31369,\n",
       " 'please': 194956,\n",
       " 'who': 275109,\n",
       " 'hosted': 124057,\n",
       " 'tournament': 255613,\n",
       " 'guy': 115097,\n",
       " 'everyone': 91872,\n",
       " 'want': 271599,\n",
       " 'think': 251496,\n",
       " 'everyday': 91842,\n",
       " 'other': 184959,\n",
       " 'fun': 104356,\n",
       " 'motivational': 167966,\n",
       " 'booster': 46277,\n",
       " 'see': 224091,\n",
       " 'cp3': 67424,\n",
       " 'ring': 214699,\n",
       " 'swaggy': 245008,\n",
       " 'hip': 121905,\n",
       " 'modern': 165875,\n",
       " 'app': 29964,\n",
       " 'apps': 30288,\n",
       " 'everything': 91916,\n",
       " 'islamic': 133272,\n",
       " 'caliphate': 52500,\n",
       " 'soon': 235274,\n",
       " 'germany': 108326,\n",
       " 'pathetic': 189172,\n",
       " 'fair': 94750,\n",
       " 'every': 91830,\n",
       " 'story': 241068,\n",
       " 'complex': 63587,\n",
       " 'final': 98245,\n",
       " 'fantasy': 95462,\n",
       " 'dare': 71933,\n",
       " 'posted': 197412,\n",
       " 'price': 199918,\n",
       " 'practical': 198366,\n",
       " 'logical': 151012,\n",
       " 'rito': 215024,\n",
       " 'falsifying': 95090,\n",
       " 'their': 250663,\n",
       " 'number': 179428,\n",
       " 'look': 151623,\n",
       " 'high': 121134,\n",
       " 'moon': 167117,\n",
       " 'side': 229640,\n",
       " 'plane': 194359,\n",
       " 'big': 42298,\n",
       " 'bucket': 49662,\n",
       " 'kenton': 140220,\n",
       " 'park': 188478,\n",
       " 'entirely': 89496,\n",
       " 'waiting': 271160,\n",
       " 'flair': 99362,\n",
       " 'change': 56702,\n",
       " 'process': 200596,\n",
       " 'pearl': 190028,\n",
       " 'harbor': 117501,\n",
       " 'apparently': 29997,\n",
       " 'speculation': 236692,\n",
       " 'galaxy': 105620,\n",
       " 'containing': 65101,\n",
       " '100': 901,\n",
       " 'billion': 42630,\n",
       " 'star': 239148,\n",
       " 'normal': 177935,\n",
       " 'continuously': 65247,\n",
       " 'fly': 100345,\n",
       " 'another': 28162,\n",
       " 'dunno': 84360,\n",
       " 'anymore': 29460,\n",
       " 'antisemitic': 29112,\n",
       " 'speech': 236705,\n",
       " 'tolerated': 254457,\n",
       " 'excellent': 92414,\n",
       " 'article': 31826,\n",
       " 'summarizes': 243435,\n",
       " 'beard': 39365,\n",
       " 'love': 152183,\n",
       " 'illidan': 127836,\n",
       " 'such': 242954,\n",
       " 'stark': 239247,\n",
       " 'contrast': 65320,\n",
       " 'arya': 32000,\n",
       " 'hold': 122872,\n",
       " 'particular': 188698,\n",
       " 'opinion': 183713,\n",
       " 'obvi': 180496,\n",
       " 'dude': 83883,\n",
       " 'learn': 146864,\n",
       " 'recognize': 208977,\n",
       " 'sarcasm': 220840,\n",
       " 'git': 109617,\n",
       " 'gud': 114345,\n",
       " 'pln': 195157,\n",
       " 'svn': 244948,\n",
       " 'sec': 223784,\n",
       " 'ahd': 23477,\n",
       " 'call': 52508,\n",
       " 'duty': 84652,\n",
       " 'black': 43554,\n",
       " 'having': 118457,\n",
       " 'zombie': 284291,\n",
       " 'always': 26072,\n",
       " 'solution': 234822,\n",
       " 'nerve': 173430,\n",
       " 'suggest': 243178,\n",
       " 'lesbian': 147945,\n",
       " 'homosexual': 123327,\n",
       " 'paying': 189586,\n",
       " 'attention': 33648,\n",
       " 'part': 188629,\n",
       " 'scummy': 223361,\n",
       " 'wait': 271126,\n",
       " 'whats': 274459,\n",
       " 'giving': 109697,\n",
       " 'liquid': 149969,\n",
       " 'behind': 40153,\n",
       " 'care': 53897,\n",
       " 'saudi': 221231,\n",
       " 'arabia': 30529,\n",
       " 'ally': 25487,\n",
       " 'bitch': 43198,\n",
       " 'pls': 195231,\n",
       " 'synthesize': 245858,\n",
       " 'own': 186558,\n",
       " 'kick': 140905,\n",
       " 'snare': 233545,\n",
       " 'hi': 120957,\n",
       " 'hat': 118145,\n",
       " 'bassdrop': 38386,\n",
       " 'lyric': 153691,\n",
       " 'pull': 203010,\n",
       " 'yourself': 282506,\n",
       " 'bootstrap': 46341,\n",
       " 'brittnees': 48573,\n",
       " 'first': 98804,\n",
       " 'genuine': 108089,\n",
       " 'unscripted': 264122,\n",
       " 'dr': 82286,\n",
       " 'dallas': 71403,\n",
       " 'loud': 152091,\n",
       " 'jesus': 135913,\n",
       " 'christ': 58826,\n",
       " 'eh': 86813,\n",
       " 'eat': 85569,\n",
       " 'lol': 151146,\n",
       " 'wondering': 277250,\n",
       " 'im': 128006,\n",
       " 'subbed': 242409,\n",
       " 'alot': 25634,\n",
       " 'seen': 224197,\n",
       " 'uploaded': 264897,\n",
       " 'online': 183008,\n",
       " 'playlist': 194821,\n",
       " 'living': 150384,\n",
       " 'back': 36057,\n",
       " 'listen': 150061,\n",
       " 'postexperimental': 197445,\n",
       " 'electronic': 87420,\n",
       " 'jazzcore': 135334,\n",
       " 'taste': 247579,\n",
       " 'music': 169964,\n",
       " 'die': 77634,\n",
       " 'swat': 245118,\n",
       " 'extraction': 93579,\n",
       " 'carry': 54307,\n",
       " 'pump': 203090,\n",
       " '12': 2409,\n",
       " 'ga': 105263,\n",
       " 'mention': 161258,\n",
       " 'audrey': 33929,\n",
       " 'totally': 255402,\n",
       " 'blew': 44210,\n",
       " 'cover': 67255,\n",
       " 'nice': 174466,\n",
       " 'very': 268251,\n",
       " 'using': 265762,\n",
       " 'biodegradable': 42837,\n",
       " 'hypodermic': 126202,\n",
       " 'needle': 172772,\n",
       " 'sleep': 232209,\n",
       " 'friend': 102969,\n",
       " 'him': 121684,\n",
       " 'those': 251948,\n",
       " 'metric': 162022,\n",
       " 'mile': 163325,\n",
       " 'makeup': 155385,\n",
       " 'needed': 172756,\n",
       " 'jinbe': 136349,\n",
       " 'into': 131990,\n",
       " 'sabo': 219301,\n",
       " 'canadian': 52987,\n",
       " 'full': 104161,\n",
       " 'bagel': 36638,\n",
       " 'maple': 156803,\n",
       " 'smoked': 233217,\n",
       " 'strip': 241739,\n",
       " 'bacon': 36354,\n",
       " 'ham': 116713,\n",
       " 'homefries': 123131,\n",
       " 'orange': 184107,\n",
       " 'juice': 137680,\n",
       " 'coffee': 61916,\n",
       " 'egg': 86683,\n",
       " 'sausage': 221281,\n",
       " 'link': 149765,\n",
       " 'pointing': 195747,\n",
       " 'flaw': 99701,\n",
       " 'rather': 207198,\n",
       " 'dismissing': 79200,\n",
       " 'sense': 225352,\n",
       " 'thank': 250186,\n",
       " 'lie': 148839,\n",
       " 'constantly': 64955,\n",
       " 'while': 274729,\n",
       " 'undermining': 262430,\n",
       " 'possible': 197265,\n",
       " 'opportunity': 183848,\n",
       " 'shot': 228860,\n",
       " 'andor': 27374,\n",
       " 'stabbed': 238717,\n",
       " 'america': 26439,\n",
       " 'timing': 253336,\n",
       " 'noticed': 178494,\n",
       " 'bankruptcy': 37556,\n",
       " 'judge': 137571,\n",
       " 'opposing': 183858,\n",
       " 'lawyer': 146420,\n",
       " 'gave': 106963,\n",
       " 'travis': 256822,\n",
       " 'benjamin': 40813,\n",
       " 'half': 116362,\n",
       " 'yard': 280932,\n",
       " 'season': 223665,\n",
       " 'many': 156727,\n",
       " 'crowd': 68898,\n",
       " 'far': 95546,\n",
       " 'vote': 270218,\n",
       " 'donald': 80877,\n",
       " 'trump': 258150,\n",
       " 'within': 276669,\n",
       " '15': 3753,\n",
       " 'port': 197007,\n",
       " 'hated': 118190,\n",
       " 'different': 77795,\n",
       " 'color': 62489,\n",
       " 'way': 272586,\n",
       " 'easy': 85524,\n",
       " 'understand': 262517,\n",
       " 'nah': 171049,\n",
       " 'power': 197994,\n",
       " 'bill': 42598,\n",
       " 'computer': 63747,\n",
       " 'whore': 275283,\n",
       " 'too': 254738,\n",
       " 'conspiracy': 64906,\n",
       " 'drum': 83391,\n",
       " 'sale': 219939,\n",
       " 'scott': 222853,\n",
       " 'pilgrim': 193385,\n",
       " 'werent': 273939,\n",
       " 'chemical': 57610,\n",
       " 'remember': 211228,\n",
       " 'extent': 93502,\n",
       " 'law': 146329,\n",
       " 'involves': 132393,\n",
       " 'family': 95167,\n",
       " 'billed': 42613,\n",
       " 'execution': 92633,\n",
       " 'bullet': 50188,\n",
       " 'imprisoned': 128757,\n",
       " 'tivo': 253803,\n",
       " 'roamio': 215637,\n",
       " 'pro': 200398,\n",
       " 'ivory': 134152,\n",
       " 'tower': 255691,\n",
       " 'liberal': 148569,\n",
       " 'gravitated': 112797,\n",
       " 'towards': 255668,\n",
       " 'obscure': 180408,\n",
       " 'religion': 211043,\n",
       " 'nobody': 175601,\n",
       " 'around': 31511,\n",
       " 'knew': 142274,\n",
       " 'seem': 224172,\n",
       " 'intelligent': 131409,\n",
       " 'find': 98317,\n",
       " 'truth': 258336,\n",
       " 'jailbreak': 134687,\n",
       " 'available': 34775,\n",
       " 'joint': 136877,\n",
       " 'closer': 61052,\n",
       " 'uncoachable': 262089,\n",
       " 'strong': 241804,\n",
       " 'enough': 89290,\n",
       " 'type': 260097,\n",
       " 'cap': 53387,\n",
       " 'mirai': 164409,\n",
       " 'nikki': 174986,\n",
       " 'xddddddddddddddddddddddd': 279830,\n",
       " 'relevant': 210978,\n",
       " 'company': 63338,\n",
       " 'apple': 30092,\n",
       " 'google': 111527,\n",
       " 'let': 148071,\n",
       " 'hand': 116913,\n",
       " 'over': 185738,\n",
       " 'key': 140472,\n",
       " 'economy': 85948,\n",
       " 'manage': 155955,\n",
       " 'neither': 173074,\n",
       " 'campaign': 52835,\n",
       " 'finance': 98278,\n",
       " 'nor': 177855,\n",
       " 'tax': 247768,\n",
       " 'return': 213096,\n",
       " 'go': 110456,\n",
       " 'running': 218331,\n",
       " 'horrible': 123880,\n",
       " 'darwinism': 72217,\n",
       " 'report': 211841,\n",
       " 'detected': 76467,\n",
       " 'basically': 38303,\n",
       " 'cryptic': 69206,\n",
       " 'command': 62940,\n",
       " 'dick': 77375,\n",
       " 'join': 136863,\n",
       " 'together': 254304,\n",
       " 'being': 40207,\n",
       " 'pisspoor': 193884,\n",
       " 'quality': 204371,\n",
       " 'life': 148914,\n",
       " 'buy': 51480,\n",
       " 'used': 265576,\n",
       " 'gamestop': 106146,\n",
       " 'method': 161972,\n",
       " 'refund': 210176,\n",
       " 'mi': 162382,\n",
       " 'elmo': 87794,\n",
       " 'oc': 180541,\n",
       " 'donut': 81119,\n",
       " 'steel': 239891,\n",
       " 'government': 112043,\n",
       " 'trust': 258311,\n",
       " 'work': 277645,\n",
       " 'harder': 117587,\n",
       " 'wanted': 271608,\n",
       " 'reinhart': 210639,\n",
       " 'gimu': 109373,\n",
       " 'translation': 256509,\n",
       " 'frolic': 103247,\n",
       " 'emperor': 88384,\n",
       " 'kira': 141679,\n",
       " 'joke': 136914,\n",
       " 'received': 208765,\n",
       " 'resend': 212296,\n",
       " 'said': 219711,\n",
       " 'al': 24316,\n",
       " 'gore': 111731,\n",
       " 'varyslittlefinger': 267172,\n",
       " 'magically': 154759,\n",
       " 'teleporting': 248885,\n",
       " 'westeros': 274082,\n",
       " 'daydreaming': 72619,\n",
       " 'meanwhile': 159770,\n",
       " 'arrow': 31682,\n",
       " 'telling': 248952,\n",
       " 'umbrella': 261537,\n",
       " 'contain': 65095,\n",
       " 'three': 252188,\n",
       " 'spell': 236845,\n",
       " 'buddha': 49737,\n",
       " 'cool': 65643,\n",
       " 'haha': 115954,\n",
       " 'ok': 181806,\n",
       " 'bro': 48591,\n",
       " 'wow': 278512,\n",
       " 'saw': 221397,\n",
       " 'removing': 211377,\n",
       " 'roadhog': 215589,\n",
       " 'improvement': 128780,\n",
       " 'meta': 161747,\n",
       " 'post': 197301,\n",
       " 'missing': 164865,\n",
       " 'hilarious': 121533,\n",
       " 'reportable': 211842,\n",
       " 'warms': 271870,\n",
       " 'heart': 119189,\n",
       " 'master': 157917,\n",
       " 'race': 205426,\n",
       " 'why': 275372,\n",
       " 'these': 251170,\n",
       " 'poor': 196664,\n",
       " 'joe': 136719,\n",
       " 'job': 136608,\n",
       " 're': 207967,\n",
       " 'ignored': 127452,\n",
       " 'duplicate': 84433,\n",
       " 'hovered': 124427,\n",
       " 'trap': 256666,\n",
       " 'happens': 117373,\n",
       " 'ill': 127757,\n",
       " 'few': 97507,\n",
       " 'day': 72579,\n",
       " 'jerk': 135785,\n",
       " 'weird': 273459,\n",
       " 'alt': 25833,\n",
       " 'safe': 219544,\n",
       " 'space': 236122,\n",
       " '5': 13299,\n",
       " 'skating': 231222,\n",
       " 'shoe': 228541,\n",
       " 'memeing': 160920,\n",
       " 'fapped': 95515,\n",
       " 'ohh': 181557,\n",
       " '360': 10669,\n",
       " 'texture': 249952,\n",
       " 'blend': 44165,\n",
       " 'youre': 282473,\n",
       " 'optimistic': 184001,\n",
       " 'jill': 136281,\n",
       " 'stein': 240014,\n",
       " 'red': 209248,\n",
       " 'state': 239432,\n",
       " 'smc': 233001,\n",
       " 'chest': 57735,\n",
       " 'cycle': 70661,\n",
       " 'worry': 277956,\n",
       " 'cantilevered': 53332,\n",
       " 'problem': 200496,\n",
       " 'win': 276020,\n",
       " '4': 11605,\n",
       " 'row': 217190,\n",
       " 'amazing': 26243,\n",
       " 'lenny': 147795,\n",
       " 'face': 94238,\n",
       " 'thunderdevil': 252543,\n",
       " 'ruin': 218084,\n",
       " 'wing': 276204,\n",
       " 'sexy': 226346,\n",
       " 'titan': 253645,\n",
       " 'nile': 175022,\n",
       " 'ranger': 206655,\n",
       " 'moment': 166361,\n",
       " 'goblin': 110607,\n",
       " 'cook': 65609,\n",
       " 'mass': 157817,\n",
       " 'valks': 266692,\n",
       " 'butthole': 51325,\n",
       " 'clench': 60590,\n",
       " 'fear': 96494,\n",
       " 'xd': 279809,\n",
       " 'afford': 22618,\n",
       " 'tragedy': 256102,\n",
       " 'barter': 38145,\n",
       " 'window': 276107,\n",
       " 'connector': 64558,\n",
       " 'repin': 211738,\n",
       " 'mobo': 165721,\n",
       " 'header': 118914,\n",
       " 'grrrrrrr': 113887,\n",
       " 'actual': 21468,\n",
       " 'reaction': 208050,\n",
       " 'any': 29424,\n",
       " 'her': 120198,\n",
       " 'shaky': 226791,\n",
       " 'talking': 246830,\n",
       " 'ellum': 87781,\n",
       " 'fake': 94862,\n",
       " 'till': 253023,\n",
       " 'did': 77541,\n",
       " 'fire': 98557,\n",
       " 'asking': 32384,\n",
       " 'raise': 206165,\n",
       " 'nuanced': 179230,\n",
       " 'pursuit': 203471,\n",
       " 'handled': 117017,\n",
       " 'properly': 201441,\n",
       " 'small': 232791,\n",
       " 'badly': 36522,\n",
       " 'burn': 50629,\n",
       " 'bridge': 48282,\n",
       " 'yea': 281125,\n",
       " 'democrat': 75178,\n",
       " 'gerrymandered': 108377,\n",
       " 'spoiler': 237462,\n",
       " 'alert': 24689,\n",
       " 'la': 144610,\n",
       " 'land': 145376,\n",
       " 'guess': 114383,\n",
       " 'our': 185144,\n",
       " 'fault': 96123,\n",
       " 'theyre': 251269,\n",
       " 'shopped': 228724,\n",
       " 'yuh': 282786,\n",
       " 'lot': 152033,\n",
       " 'called': 52528,\n",
       " 'narcissist': 171617,\n",
       " 'worth': 278028,\n",
       " 'aggressive': 23152,\n",
       " 'catching': 54879,\n",
       " 'arguably': 31080,\n",
       " 'most': 167765,\n",
       " 'balanced': 36933,\n",
       " 'least': 146907,\n",
       " 'abused': 20574,\n",
       " 'mechanic': 159897,\n",
       " 'ea': 85154,\n",
       " 'settle': 226048,\n",
       " 'city': 59844,\n",
       " '20': 6244,\n",
       " 'kid': 140957,\n",
       " 'writing': 278858,\n",
       " 'witch': 276590,\n",
       " 'aim': 23715,\n",
       " 'down': 81929,\n",
       " 'sight': 229868,\n",
       " 'awesome': 35129,\n",
       " 'try': 258390,\n",
       " 'word': 277572,\n",
       " 'measured': 159804,\n",
       " 'peyton': 192039,\n",
       " 'throwing': 252384,\n",
       " '7': 15924,\n",
       " 'pick': 192958,\n",
       " '3': 9436,\n",
       " 'tds': 248061,\n",
       " 'lone': 151402,\n",
       " 'wasnt': 272140,\n",
       " 'example': 92318,\n",
       " 'jealous': 135426,\n",
       " 'mario': 157162,\n",
       " 'balotelli': 37201,\n",
       " 'stem': 240049,\n",
       " 'field': 97850,\n",
       " 'kindly': 141462,\n",
       " 'lebron': 147010,\n",
       " 'james': 134841,\n",
       " 'willing': 275926,\n",
       " 'million': 163556,\n",
       " 'contract': 65272,\n",
       " 'allowed': 25363,\n",
       " 'disproportionate': 79346,\n",
       " 'force': 101073,\n",
       " 'logic': 151010,\n",
       " 'oppressive': 183894,\n",
       " 'invalidates': 132184,\n",
       " 'experience': 93118,\n",
       " 'dceu': 72882,\n",
       " 'dead': 73093,\n",
       " 'bury': 50764,\n",
       " 'obvious': 180508,\n",
       " 'viral': 269219,\n",
       " 'centipede': 55889,\n",
       " 'gd7f': 107276,\n",
       " 'requires': 212144,\n",
       " 'heartbeat': 119195,\n",
       " 'as': 32011,\n",
       " 'turd': 259125,\n",
       " ...}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By using the following dict, we can obtain the index of a given word for querying tfidf matrix.\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once we have learned word vectors, to compute the sentence vector of a comment,\n",
    "first fetch the corresponding row from the tfidf matrix (if it is the i-th original comment, then\n",
    "it is the i-th row; if it is the i-th parent comment, then it is the (1010773 + i)-th row),\n",
    "second for each word in the comment find its corresponding tfidf value from the row,\n",
    "third compute the average of the word vectors weighted by corresponding tfidf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212926, 284779)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrix[0,249920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250360"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['thats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfMatrixtest = tfidfVectorizer.transform(pd.concat([X_test['comment_tokens'], X_test['parent_comment_tokens']]))\n",
    "tfidfMatrixvalid = tfidfVectorizer.transform(pd.concat([X_val['comment_tokens'], X_val['parent_comment_tokens']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404310, 284779)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrixtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_tokens</th>\n",
       "      <th>parent_comment_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[howdoyouhavesoprettyvoicethoholycrap]</td>\n",
       "      <td>[this, is, a, first, for, me, a, cover, of, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ive, never, heard, of, a, parallel, bible]</td>\n",
       "      <td>[try, a, parallel, bible, maybe, one, with, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, saw, this, at, best, buy, but, could, not,...</td>\n",
       "      <td>[ha, anyone, heard, of, the, corsair, k65, lux]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[so, when, people, now, a, day, say, they, spe...</td>\n",
       "      <td>[that, statement, is, not, accurate, and, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wooooooow, this, sub, is, soooooo, bad, now]</td>\n",
       "      <td>[we, are, getting, a, new, steve, job, movie, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[by, looking, at, the, ground]</td>\n",
       "      <td>[i, think, it, a, lottery, i, can, run, it, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[voivod, the, outer, limit, frank, black, teen...</td>\n",
       "      <td>[what, 5, album, not, currently, or, easily, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[yeah, because, thug, against, thug, is, equal...</td>\n",
       "      <td>[yeah, i, agree, it, like, in, ww2, you, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[you, would, catch, more, if, you, used, high,...</td>\n",
       "      <td>[bait, the, cop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[what, is, the, airspeed, velocity, of, an, un...</td>\n",
       "      <td>[a, lot, of, kevin, morby, it, seems, like]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_tokens  \\\n",
       "0             [howdoyouhavesoprettyvoicethoholycrap]   \n",
       "1        [ive, never, heard, of, a, parallel, bible]   \n",
       "2  [i, saw, this, at, best, buy, but, could, not,...   \n",
       "3  [so, when, people, now, a, day, say, they, spe...   \n",
       "4      [wooooooow, this, sub, is, soooooo, bad, now]   \n",
       "5                     [by, looking, at, the, ground]   \n",
       "6  [voivod, the, outer, limit, frank, black, teen...   \n",
       "7  [yeah, because, thug, against, thug, is, equal...   \n",
       "8  [you, would, catch, more, if, you, used, high,...   \n",
       "9  [what, is, the, airspeed, velocity, of, an, un...   \n",
       "\n",
       "                               parent_comment_tokens  \n",
       "0  [this, is, a, first, for, me, a, cover, of, on...  \n",
       "1  [try, a, parallel, bible, maybe, one, with, an...  \n",
       "2    [ha, anyone, heard, of, the, corsair, k65, lux]  \n",
       "3  [that, statement, is, not, accurate, and, is, ...  \n",
       "4  [we, are, getting, a, new, steve, job, movie, ...  \n",
       "5  [i, think, it, a, lottery, i, can, run, it, fi...  \n",
       "6  [what, 5, album, not, currently, or, easily, a...  \n",
       "7  [yeah, i, agree, it, like, in, ww2, you, might...  \n",
       "8                                   [bait, the, cop]  \n",
       "9        [a, lot, of, kevin, morby, it, seems, like]  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101035"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['for']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrixtest[0, 100573]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(X, tfidfmat):\n",
    "    comment_featurevec = []\n",
    "    parent_featurevec = []\n",
    "    \n",
    "    for index, sample in X.iterrows():\n",
    "        \n",
    "        comment_vec = np.zeros(300)\n",
    "        parent_comment_vec = np.zeros(300)\n",
    "        comment_tokens = sample['comment_tokens']\n",
    "        parent_comment_tokens = sample['parent_comment_tokens']\n",
    "        counter1 = 0\n",
    "        \n",
    "        for token in comment_tokens:\n",
    "            \n",
    "            if token in glove and token in vocabulary:\n",
    "                counter1 += 1\n",
    "                comment_vec += tfidfmat[index, vocabulary[token]] * glove[token]\n",
    "        \n",
    "        counter2 = 0\n",
    "        for token in parent_comment_tokens:\n",
    "            \n",
    "            if token in glove and token in vocabulary:\n",
    "                counter2 += 1 \n",
    "                parent_comment_vec += tfidfmat[index+len(X), vocabulary[token]] * glove[token]\n",
    "        \n",
    "        if counter1 != 0:\n",
    "            comment_featurevec.append(comment_vec/counter1)\n",
    "        else:\n",
    "            comment_featurevec.append(comment_vec)\n",
    "        \n",
    "        if counter2 != 0:\n",
    "            parent_featurevec.append(parent_comment_vec/counter2)\n",
    "        else:\n",
    "            parent_featurevec.append(parent_comment_vec)\n",
    "            \n",
    "        \n",
    "    #print(len(comment_featurevec))\n",
    "    X['comment_weighted_vec'] = comment_featurevec\n",
    "    X['parent_weighted_vec'] = parent_featurevec\n",
    "    new_df = pd.DataFrame()\n",
    "        \n",
    "    return X\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = generate_dataset(X_train, tfidfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = generate_dataset(X_val, tfidfMatrixvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = generate_dataset(X_test, tfidfMatrixtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['comment_weighted_vec', 'parent_weighted_vec']]\n",
    "X_val = X_val[['comment_weighted_vec', 'parent_weighted_vec']]\n",
    "X_test = X_test[['comment_weighted_vec', 'parent_weighted_vec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(dataset):\n",
    "    x = pd.DataFrame(dataset['parent_weighted_vec'].tolist(), columns = [i for i in range(300)])\n",
    "    y = pd.DataFrame(dataset['comment_weighted_vec'].tolist(), columns = [i for i in range(300, 600)])\n",
    "    return pd.concat([x, y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = featurize(X_train)\n",
    "X_val = featurize(X_val)\n",
    "X_test = featurize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 500).fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5967895921446414"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5971507011946279"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test.iloc[2].values.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "202150    0\n",
       "202151    0\n",
       "202152    0\n",
       "202153    1\n",
       "202154    1\n",
       "Name: label, Length: 202155, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        \n",
    "        self.z1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.z2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.z3 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.sig(self.z1(x))\n",
    "        out = self.relu(self.z2(out))\n",
    "        out = self.z3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 600\n",
    "hidden_dim = 128\n",
    "output_dim = 2\n",
    "num_epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "ff_nn_model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ff_nn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch completed: 1\n",
      "Epoch completed: 2\n",
      "Epoch completed: 3\n",
      "Epoch completed: 4\n",
      "Epoch completed: 5\n",
      "Epoch completed: 6\n",
      "Epoch completed: 7\n",
      "Epoch completed: 8\n",
      "Epoch completed: 9\n",
      "Epoch completed: 10\n",
      "Epoch completed: 11\n",
      "Epoch completed: 12\n",
      "Epoch completed: 13\n",
      "Epoch completed: 14\n",
      "Epoch completed: 15\n",
      "Epoch completed: 16\n",
      "Epoch completed: 17\n",
      "Epoch completed: 18\n",
      "Epoch completed: 19\n",
      "Epoch completed: 20\n",
      "Epoch completed: 21\n",
      "Epoch completed: 22\n",
      "Epoch completed: 23\n",
      "Epoch completed: 24\n",
      "Epoch completed: 25\n",
      "Epoch completed: 26\n",
      "Epoch completed: 27\n",
      "Epoch completed: 28\n",
      "Epoch completed: 29\n",
      "Epoch completed: 30\n",
      "Epoch completed: 31\n",
      "Epoch completed: 32\n",
      "Epoch completed: 33\n",
      "Epoch completed: 34\n",
      "Epoch completed: 35\n",
      "Epoch completed: 36\n",
      "Epoch completed: 37\n",
      "Epoch completed: 38\n",
      "Epoch completed: 39\n",
      "Epoch completed: 40\n",
      "Epoch completed: 41\n",
      "Epoch completed: 42\n",
      "Epoch completed: 43\n",
      "Epoch completed: 44\n",
      "Epoch completed: 45\n",
      "Epoch completed: 46\n",
      "Epoch completed: 47\n",
      "Epoch completed: 48\n",
      "Epoch completed: 49\n",
      "Epoch completed: 50\n",
      "606399\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch completed: \" + str(epoch+1))\n",
    "    train_loss = 0\n",
    "    inpt = []\n",
    "    size = int(X_train.shape[0])\n",
    "    for index, row in X_train.iterrows():\n",
    "        inpt.append(row)\n",
    "        if (index + 1) % batch_size == 0:\n",
    "            output = ff_nn_model(torch.Tensor(inpt))\n",
    "            label = torch.tensor(list(y_train['label'].values)[index:index+batch_size])\n",
    "            print(index, end=\"\\r\")\n",
    "            if len(label) < batch_size:\n",
    "               break\n",
    "            optimizer.zero_grad() \n",
    "            loss = loss_fn(output, label)\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            inpt = []\n",
    "    \n",
    "            train_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202155 202155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.79      0.61    101318\n",
      "           1       0.46      0.18      0.26    100837\n",
      "\n",
      "    accuracy                           0.49    202155\n",
      "   macro avg       0.48      0.49      0.43    202155\n",
      "weighted avg       0.48      0.49      0.43    202155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = []\n",
    "labels = torch.tensor(list(y_test['label'].values))\n",
    "with torch.no_grad():\n",
    "    for index, row in X_test.iterrows():\n",
    "        output = ff_nn_model(torch.Tensor(row))\n",
    "        preds.append(torch.argmax(output, dim=0))\n",
    "        \n",
    "print(len(labels), len(preds))\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
